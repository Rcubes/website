<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>datacubeR on datacubeR</title>
    <link>/</link>
    <description>Recent content in datacubeR on datacubeR</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator>
    <language>en-us</language>
    <copyright> &lt;i class=&#39;fab fa-creative-commons fa-2x&#39;&gt;&lt;/i&gt;&lt;i class=&#39;fab fa-creative-commons-by fa-2x&#39;&gt;&lt;/i&gt;&lt;i class=&#39;fab fa-creative-commons-sa fa-2x&#39;&gt;&lt;/i&gt;&lt;br&gt;&amp;copy;Alfonso Tobar. Made with &lt;i class=&#39;fab fa-r-project&#39;&gt;&lt;/i&gt; Blogdown Package.</copyright>
    <lastBuildDate>Wed, 30 Oct 2019 00:00:00 +0000</lastBuildDate>
    <atom:link href="/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Dealing with dates</title>
      <link>/publication/problem-7/</link>
      <pubDate>Wed, 30 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>/publication/problem-7/</guid>
      <description>
&lt;link href=&#34;/rmarkdown-libs/pagedtable/css/pagedtable.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;script src=&#34;/rmarkdown-libs/pagedtable/js/pagedtable.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;the-problem&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The Problem&lt;/h2&gt;
&lt;p&gt;Here is the challenge:&lt;/p&gt;
&lt;p&gt;Calculate the time difference between Max and Min Dates found in a date vector.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
date_vec &amp;lt;- c(&amp;quot;2019/10/24 10:00:00&amp;quot;,&amp;quot;2019/10/23 11:00:00&amp;quot;,&amp;quot;2019/10/25 12:00:00&amp;quot;) &lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;the-solution&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The Solution&lt;/h2&gt;
&lt;p&gt;The thing is super easy to get, but the idea is to create a pipeline that can calculate this in just a series of steps:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(lubridate)

date_vec %&amp;gt;%
  #Transforming characters into dates using ymd for dates and hms for time
  ymd_hms() %&amp;gt;%
  #range() retrieves max and min date
  range() %&amp;gt;%
  #Calculate the time difference
  diff() %&amp;gt;%
  #Transform into lubridate duration object %&amp;gt;%
   as.duration() &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;176400s (~2.04 days)&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>I got a new Job!!</title>
      <link>/post/new-job/</link>
      <pubDate>Wed, 30 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/new-job/</guid>
      <description>

&lt;h2 id=&#34;my-new-job&#34;&gt;My new Job&lt;/h2&gt;

&lt;p&gt;My working relationship with Evalueserve ended the past June and I just dedicated to finish my Thesis. On the first days of October I just started to apply to different Jobs, I have to say my first option was trying to get a Job at H2o, but I¬¥m not there yet.&lt;/p&gt;

&lt;p&gt;The thing is that after the first Interview I knew this would be my new Company, I felt some kind of feeling saying &amp;ldquo;&lt;em&gt;you will work here&lt;/em&gt;&amp;rdquo; (although I had some hesitation). So I will be a &lt;strong&gt;Senior Data Scientist&lt;/strong&gt; working at Scotiabank Cencosud, a Retail Company, and I¬¥ll be part of the Advanced Analytics Team.&lt;/p&gt;

&lt;p&gt;It seems there is a lot of interesting opportunities for my carreer. So let¬¥s break them down:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;This is a real Modeling Position.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;I will be primarily involved in developing Machine Learning in Production. This is something super exciting because I think I have learned and practiced a lot to be involved into this. I feel super prepared and eager to start applying the knowledge learned in the POCs I¬¥ve worked in EVS and in the ML Diploma.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;We¬¥ll have a real Data Lake with plenty of Data&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;This is important, I don¬¥t remember where I read about the things I needed to pay attention when applying to a new Job, and of course if we are doing Data Science we need Data. Well Cencosud is a Company that is positioning itself as an IDO (Insight Driven organization) and its primary focus is to make Data Driven Decisions.&lt;/p&gt;

&lt;p&gt;I think, I will have the chance to work with large amounts of Data and hopefully use Spark, this is something I really want to incorporate into my skill set.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;There¬¥s space for Innovative Research&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;At least in my conversations with the High Management during Interviews they guaranteed some space to innovate and experiment. This is something really fun to me and that I was looking for. So I expect to have the opportunity to implement new models, or algorithms that i haven¬¥t work with before.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;I will use R&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;This was a main thing to me. I applied to several position where R was not an option, but I just couldn¬¥t stand it. I want to work with R, and here I will have the opportunity to use it from end to end. I even twitted about it üòú and I got one üòÅ.&lt;/p&gt;

&lt;p&gt;&lt;center&gt;
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;- I want/need a new job. üòï&lt;br&gt;- I don&amp;#39;t mind what area: Data cleaning, process automations, data reporting, data visualization, machine learning, deep learning, long etc.ü§î&lt;br&gt;- but I want to use &lt;a href=&#34;https://twitter.com/hashtag/rstats?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#rstats&lt;/a&gt;.üòÖ&lt;br&gt;&lt;br&gt;Is that a crime?&lt;a href=&#34;https://twitter.com/hashtag/rstats?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#rstats&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/hashtag/rstatses?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#rstatses&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/LatinR_Conf?ref_src=twsrc%5Etfw&#34;&gt;@LatinR_Conf&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/hashtag/newjobplease?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#newjobplease&lt;/a&gt; ü§îüôÑüòÖü§®üòÅ&lt;/p&gt;&amp;mdash; Alfonso Tobar (@tobar_with_R) &lt;a href=&#34;https://twitter.com/tobar_with_R/status/1183107543113093120?ref_src=twsrc%5Etfw&#34;&gt;October 12, 2019&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;

&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;Many thanks to all the people that provided assitance and help to find job opportunities.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;I¬¥m well paid and with plenty of Benefits&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Of course I will not disclose my salary (to avoid jealousy ), but I feel happy with the Offering. This was really an issue in my previous job, so I expect good things to happen in here.&lt;/p&gt;

&lt;p&gt;More to come after the first month, I think, but at least for now. &lt;strong&gt;I¬¥m happy&lt;/strong&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Unique Id Challenge</title>
      <link>/publication/problem-8/</link>
      <pubDate>Wed, 30 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>/publication/problem-8/</guid>
      <description>
&lt;link href=&#34;/rmarkdown-libs/pagedtable/css/pagedtable.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;script src=&#34;/rmarkdown-libs/pagedtable/js/pagedtable.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;the-problem&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The Problem&lt;/h2&gt;
&lt;p&gt;Another Twitter Challenge:&lt;/p&gt;
&lt;center&gt;
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;&lt;a href=&#34;https://twitter.com/hashtag/rstats?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#rstats&lt;/a&gt; I&amp;#39;m sure there&amp;#39;s an elegant solution that I&amp;#39;m just totally missing. How do I create a unique episode_ID that increases by 1 for instances where episode_flag == &amp;quot;new&amp;quot; but just repeats the value from the row above when episode_flag == &amp;quot;same&amp;quot;? &lt;a href=&#34;https://t.co/Dl5ZtAiE7J&#34;&gt;pic.twitter.com/Dl5ZtAiE7J&lt;/a&gt;&lt;/p&gt;&amp;mdash; Jessica Streeter (@phillynerd) &lt;a href=&#34;https://twitter.com/phillynerd/status/1189641234639400961?ref_src=twsrc%5Etfw&#34;&gt;October 30, 2019&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;

&lt;/center&gt;
&lt;/div&gt;
&lt;div id=&#34;the-solution&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The Solution&lt;/h2&gt;
&lt;p&gt;It is almost there, I just added a couple of lines to get the expected output elegantly:&lt;/p&gt;
&lt;div data-pagedtable=&#34;false&#34;&gt;
&lt;script data-pagedtable-source type=&#34;application/json&#34;&gt;
{&#34;columns&#34;:[{&#34;label&#34;:[&#34;member&#34;],&#34;name&#34;:[1],&#34;type&#34;:[&#34;chr&#34;],&#34;align&#34;:[&#34;left&#34;]},{&#34;label&#34;:[&#34;appt&#34;],&#34;name&#34;:[2],&#34;type&#34;:[&#34;chr&#34;],&#34;align&#34;:[&#34;left&#34;]},{&#34;label&#34;:[&#34;episode_flag&#34;],&#34;name&#34;:[3],&#34;type&#34;:[&#34;chr&#34;],&#34;align&#34;:[&#34;left&#34;]}],&#34;data&#34;:[{&#34;1&#34;:&#34;a&#34;,&#34;2&#34;:&#34;1&#34;,&#34;3&#34;:&#34;new&#34;},{&#34;1&#34;:&#34;a&#34;,&#34;2&#34;:&#34;2&#34;,&#34;3&#34;:&#34;same&#34;},{&#34;1&#34;:&#34;b&#34;,&#34;2&#34;:&#34;1&#34;,&#34;3&#34;:&#34;new&#34;},{&#34;1&#34;:&#34;b&#34;,&#34;2&#34;:&#34;2&#34;,&#34;3&#34;:&#34;same&#34;},{&#34;1&#34;:&#34;b&#34;,&#34;2&#34;:&#34;3&#34;,&#34;3&#34;:&#34;same&#34;},{&#34;1&#34;:&#34;b&#34;,&#34;2&#34;:&#34;1&#34;,&#34;3&#34;:&#34;new&#34;},{&#34;1&#34;:&#34;c&#34;,&#34;2&#34;:&#34;1&#34;,&#34;3&#34;:&#34;new&#34;}],&#34;options&#34;:{&#34;columns&#34;:{&#34;min&#34;:{},&#34;max&#34;:[10]},&#34;rows&#34;:{&#34;min&#34;:[10],&#34;max&#34;:[10]},&#34;pages&#34;:{}}}
  &lt;/script&gt;
&lt;/div&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df %&amp;gt;%
  group_by(episode_flag) %&amp;gt;%
  mutate(episode_ID = ifelse(episode_flag ==&amp;quot;new&amp;quot;, row_number(), NA)) %&amp;gt;%
  # Eliminating groups to apply next function
  ungroup() %&amp;gt;%
  # Filling NAs with previous non-NA values
  fill(episode_ID)&lt;/code&gt;&lt;/pre&gt;
&lt;div data-pagedtable=&#34;false&#34;&gt;
&lt;script data-pagedtable-source type=&#34;application/json&#34;&gt;
{&#34;columns&#34;:[{&#34;label&#34;:[&#34;member&#34;],&#34;name&#34;:[1],&#34;type&#34;:[&#34;chr&#34;],&#34;align&#34;:[&#34;left&#34;]},{&#34;label&#34;:[&#34;appt&#34;],&#34;name&#34;:[2],&#34;type&#34;:[&#34;chr&#34;],&#34;align&#34;:[&#34;left&#34;]},{&#34;label&#34;:[&#34;episode_flag&#34;],&#34;name&#34;:[3],&#34;type&#34;:[&#34;chr&#34;],&#34;align&#34;:[&#34;left&#34;]},{&#34;label&#34;:[&#34;episode_ID&#34;],&#34;name&#34;:[4],&#34;type&#34;:[&#34;int&#34;],&#34;align&#34;:[&#34;right&#34;]}],&#34;data&#34;:[{&#34;1&#34;:&#34;a&#34;,&#34;2&#34;:&#34;1&#34;,&#34;3&#34;:&#34;new&#34;,&#34;4&#34;:&#34;1&#34;},{&#34;1&#34;:&#34;a&#34;,&#34;2&#34;:&#34;2&#34;,&#34;3&#34;:&#34;same&#34;,&#34;4&#34;:&#34;1&#34;},{&#34;1&#34;:&#34;b&#34;,&#34;2&#34;:&#34;1&#34;,&#34;3&#34;:&#34;new&#34;,&#34;4&#34;:&#34;2&#34;},{&#34;1&#34;:&#34;b&#34;,&#34;2&#34;:&#34;2&#34;,&#34;3&#34;:&#34;same&#34;,&#34;4&#34;:&#34;2&#34;},{&#34;1&#34;:&#34;b&#34;,&#34;2&#34;:&#34;3&#34;,&#34;3&#34;:&#34;same&#34;,&#34;4&#34;:&#34;2&#34;},{&#34;1&#34;:&#34;b&#34;,&#34;2&#34;:&#34;1&#34;,&#34;3&#34;:&#34;new&#34;,&#34;4&#34;:&#34;3&#34;},{&#34;1&#34;:&#34;c&#34;,&#34;2&#34;:&#34;1&#34;,&#34;3&#34;:&#34;new&#34;,&#34;4&#34;:&#34;4&#34;}],&#34;options&#34;:{&#34;columns&#34;:{&#34;min&#34;:{},&#34;max&#34;:[10]},&#34;rows&#34;:{&#34;min&#34;:[10],&#34;max&#34;:[10]},&#34;pages&#34;:{}}}
  &lt;/script&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Transposing a dataframe</title>
      <link>/publication/problem-6/</link>
      <pubDate>Thu, 24 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>/publication/problem-6/</guid>
      <description>
&lt;link href=&#34;/rmarkdown-libs/pagedtable/css/pagedtable.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;script src=&#34;/rmarkdown-libs/pagedtable/js/pagedtable.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;the-problem&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The Problem&lt;/h2&gt;
&lt;p&gt;Here is the challenge:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data &amp;lt;- data.frame(
  &amp;quot;id&amp;quot; = c(901, 902, 903, &amp;quot;age&amp;quot;, &amp;quot;gender&amp;quot;, &amp;quot;language&amp;quot;),
  &amp;quot;rater1&amp;quot; = c(7, 9, 9, 21, 1, 1),
  &amp;quot;rater2&amp;quot; = c(9, 9, 9, 39, 2, 2),
  &amp;quot;rater3&amp;quot; = c(9, 9, 9, 38, 2, 1),
  &amp;quot;rater4&amp;quot; = c(9, 9, 9, 33, 2, 1),
  &amp;quot;rater5&amp;quot; = c(2, 9, 9, 21, 2, 1)
)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Filter all the ratings with gender 1, or language 1, or gender 1 AND language 1.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;the-solution&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The Solution&lt;/h2&gt;
&lt;p&gt;The thing is super easy, we need to transpose, the thing transposition is not a valid operation when it comes to data frames, how can we apply this in a data frame using &lt;code&gt;tidyverse&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;So in order to understand what happens I will run the solution by parts.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data %&amp;gt;%
  transpose()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [[1]]
## [[1]]$id
## [1] 1
## 
## [[1]]$rater1
## [1] 7
## 
## [[1]]$rater2
## [1] 9
## 
## [[1]]$rater3
## [1] 9
## 
## [[1]]$rater4
## [1] 9
## 
## [[1]]$rater5
## [1] 2
## 
## 
## [[2]]
## [[2]]$id
## [1] 2
## 
## [[2]]$rater1
## [1] 9
## 
## [[2]]$rater2
## [1] 9
## 
## [[2]]$rater3
## [1] 9
## 
## [[2]]$rater4
## [1] 9
## 
## [[2]]$rater5
## [1] 9
## 
## 
## [[3]]
## [[3]]$id
## [1] 3
## 
## [[3]]$rater1
## [1] 9
## 
## [[3]]$rater2
## [1] 9
## 
## [[3]]$rater3
## [1] 9
## 
## [[3]]$rater4
## [1] 9
## 
## [[3]]$rater5
## [1] 9
## 
## 
## [[4]]
## [[4]]$id
## [1] 4
## 
## [[4]]$rater1
## [1] 21
## 
## [[4]]$rater2
## [1] 39
## 
## [[4]]$rater3
## [1] 38
## 
## [[4]]$rater4
## [1] 33
## 
## [[4]]$rater5
## [1] 21
## 
## 
## [[5]]
## [[5]]$id
## [1] 5
## 
## [[5]]$rater1
## [1] 1
## 
## [[5]]$rater2
## [1] 2
## 
## [[5]]$rater3
## [1] 2
## 
## [[5]]$rater4
## [1] 2
## 
## [[5]]$rater5
## [1] 2
## 
## 
## [[6]]
## [[6]]$id
## [1] 6
## 
## [[6]]$rater1
## [1] 1
## 
## [[6]]$rater2
## [1] 2
## 
## [[6]]$rater3
## [1] 1
## 
## [[6]]$rater4
## [1] 1
## 
## [[6]]$rater5
## [1] 1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The problem using transpose is that the results is a list of lists, so it¬¥s necessary to transform inner list into vectors:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data %&amp;gt;% 
  #select raters
  select(contains(&amp;quot;rater&amp;quot;)) %&amp;gt;%
  #transpose, the problem is that this transform data into lists of lists.
  transpose() %&amp;gt;%
  #unlisting into double vectors
  map(flatten_dbl)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [[1]]
## rater1 rater2 rater3 rater4 rater5 
##      7      9      9      9      2 
## 
## [[2]]
## rater1 rater2 rater3 rater4 rater5 
##      9      9      9      9      9 
## 
## [[3]]
## rater1 rater2 rater3 rater4 rater5 
##      9      9      9      9      9 
## 
## [[4]]
## rater1 rater2 rater3 rater4 rater5 
##     21     39     38     33     21 
## 
## [[5]]
## rater1 rater2 rater3 rater4 rater5 
##      1      2      2      2      2 
## 
## [[6]]
## rater1 rater2 rater3 rater4 rater5 
##      1      2      1      1      1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now every list slot can be renamed with the corresponding id:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data %&amp;gt;% 
  #select raters
  select(contains(&amp;quot;rater&amp;quot;)) %&amp;gt;%
  #transpose, the problem is that this transform data into lists of lists.
  transpose() %&amp;gt;%
  #unlisting 
  map(flatten_dbl) %&amp;gt;%
  set_names(data$id)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## $`901`
## rater1 rater2 rater3 rater4 rater5 
##      7      9      9      9      2 
## 
## $`902`
## rater1 rater2 rater3 rater4 rater5 
##      9      9      9      9      9 
## 
## $`903`
## rater1 rater2 rater3 rater4 rater5 
##      9      9      9      9      9 
## 
## $age
## rater1 rater2 rater3 rater4 rater5 
##     21     39     38     33     21 
## 
## $gender
## rater1 rater2 rater3 rater4 rater5 
##      1      2      2      2      2 
## 
## $language
## rater1 rater2 rater3 rater4 rater5 
##      1      2      1      1      1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Finally we can reorganize using map_dfc() function that reorder the data into dataframes by column:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;(
  new_data &amp;lt;- data %&amp;gt;%
    #select raters
    select(contains(&amp;quot;rater&amp;quot;)) %&amp;gt;%
    #transpose, the problem is that this transform data into lists of lists.
    transpose() %&amp;gt;%
    #unlisting
    map(flatten_dbl) %&amp;gt;%
    set_names(data$id) %&amp;gt;%
    map_dfc( ~ .x)
)&lt;/code&gt;&lt;/pre&gt;
&lt;div data-pagedtable=&#34;false&#34;&gt;
&lt;script data-pagedtable-source type=&#34;application/json&#34;&gt;
{&#34;columns&#34;:[{&#34;label&#34;:[&#34;901&#34;],&#34;name&#34;:[1],&#34;type&#34;:[&#34;dbl&#34;],&#34;align&#34;:[&#34;right&#34;]},{&#34;label&#34;:[&#34;902&#34;],&#34;name&#34;:[2],&#34;type&#34;:[&#34;dbl&#34;],&#34;align&#34;:[&#34;right&#34;]},{&#34;label&#34;:[&#34;903&#34;],&#34;name&#34;:[3],&#34;type&#34;:[&#34;dbl&#34;],&#34;align&#34;:[&#34;right&#34;]},{&#34;label&#34;:[&#34;age&#34;],&#34;name&#34;:[4],&#34;type&#34;:[&#34;dbl&#34;],&#34;align&#34;:[&#34;right&#34;]},{&#34;label&#34;:[&#34;gender&#34;],&#34;name&#34;:[5],&#34;type&#34;:[&#34;dbl&#34;],&#34;align&#34;:[&#34;right&#34;]},{&#34;label&#34;:[&#34;language&#34;],&#34;name&#34;:[6],&#34;type&#34;:[&#34;dbl&#34;],&#34;align&#34;:[&#34;right&#34;]}],&#34;data&#34;:[{&#34;1&#34;:&#34;7&#34;,&#34;2&#34;:&#34;9&#34;,&#34;3&#34;:&#34;9&#34;,&#34;4&#34;:&#34;21&#34;,&#34;5&#34;:&#34;1&#34;,&#34;6&#34;:&#34;1&#34;,&#34;_row&#34;:&#34;rater1&#34;},{&#34;1&#34;:&#34;9&#34;,&#34;2&#34;:&#34;9&#34;,&#34;3&#34;:&#34;9&#34;,&#34;4&#34;:&#34;39&#34;,&#34;5&#34;:&#34;2&#34;,&#34;6&#34;:&#34;2&#34;,&#34;_row&#34;:&#34;rater2&#34;},{&#34;1&#34;:&#34;9&#34;,&#34;2&#34;:&#34;9&#34;,&#34;3&#34;:&#34;9&#34;,&#34;4&#34;:&#34;38&#34;,&#34;5&#34;:&#34;2&#34;,&#34;6&#34;:&#34;1&#34;,&#34;_row&#34;:&#34;rater3&#34;},{&#34;1&#34;:&#34;9&#34;,&#34;2&#34;:&#34;9&#34;,&#34;3&#34;:&#34;9&#34;,&#34;4&#34;:&#34;33&#34;,&#34;5&#34;:&#34;2&#34;,&#34;6&#34;:&#34;1&#34;,&#34;_row&#34;:&#34;rater4&#34;},{&#34;1&#34;:&#34;2&#34;,&#34;2&#34;:&#34;9&#34;,&#34;3&#34;:&#34;9&#34;,&#34;4&#34;:&#34;21&#34;,&#34;5&#34;:&#34;2&#34;,&#34;6&#34;:&#34;1&#34;,&#34;_row&#34;:&#34;rater5&#34;}],&#34;options&#34;:{&#34;columns&#34;:{&#34;min&#34;:{},&#34;max&#34;:[10]},&#34;rows&#34;:{&#34;min&#34;:[10],&#34;max&#34;:[10]},&#34;pages&#34;:{}}}
  &lt;/script&gt;
&lt;/div&gt;
&lt;p&gt;Now we can filter accordingly the requested filterings:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;new_data %&amp;gt;%
  filter(gender == 1)&lt;/code&gt;&lt;/pre&gt;
&lt;div data-pagedtable=&#34;false&#34;&gt;
&lt;script data-pagedtable-source type=&#34;application/json&#34;&gt;
{&#34;columns&#34;:[{&#34;label&#34;:[&#34;901&#34;],&#34;name&#34;:[1],&#34;type&#34;:[&#34;dbl&#34;],&#34;align&#34;:[&#34;right&#34;]},{&#34;label&#34;:[&#34;902&#34;],&#34;name&#34;:[2],&#34;type&#34;:[&#34;dbl&#34;],&#34;align&#34;:[&#34;right&#34;]},{&#34;label&#34;:[&#34;903&#34;],&#34;name&#34;:[3],&#34;type&#34;:[&#34;dbl&#34;],&#34;align&#34;:[&#34;right&#34;]},{&#34;label&#34;:[&#34;age&#34;],&#34;name&#34;:[4],&#34;type&#34;:[&#34;dbl&#34;],&#34;align&#34;:[&#34;right&#34;]},{&#34;label&#34;:[&#34;gender&#34;],&#34;name&#34;:[5],&#34;type&#34;:[&#34;dbl&#34;],&#34;align&#34;:[&#34;right&#34;]},{&#34;label&#34;:[&#34;language&#34;],&#34;name&#34;:[6],&#34;type&#34;:[&#34;dbl&#34;],&#34;align&#34;:[&#34;right&#34;]}],&#34;data&#34;:[{&#34;1&#34;:&#34;7&#34;,&#34;2&#34;:&#34;9&#34;,&#34;3&#34;:&#34;9&#34;,&#34;4&#34;:&#34;21&#34;,&#34;5&#34;:&#34;1&#34;,&#34;6&#34;:&#34;1&#34;}],&#34;options&#34;:{&#34;columns&#34;:{&#34;min&#34;:{},&#34;max&#34;:[10]},&#34;rows&#34;:{&#34;min&#34;:[10],&#34;max&#34;:[10]},&#34;pages&#34;:{}}}
  &lt;/script&gt;
&lt;/div&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;new_data %&amp;gt;%
  filter(language == 1)&lt;/code&gt;&lt;/pre&gt;
&lt;div data-pagedtable=&#34;false&#34;&gt;
&lt;script data-pagedtable-source type=&#34;application/json&#34;&gt;
{&#34;columns&#34;:[{&#34;label&#34;:[&#34;901&#34;],&#34;name&#34;:[1],&#34;type&#34;:[&#34;dbl&#34;],&#34;align&#34;:[&#34;right&#34;]},{&#34;label&#34;:[&#34;902&#34;],&#34;name&#34;:[2],&#34;type&#34;:[&#34;dbl&#34;],&#34;align&#34;:[&#34;right&#34;]},{&#34;label&#34;:[&#34;903&#34;],&#34;name&#34;:[3],&#34;type&#34;:[&#34;dbl&#34;],&#34;align&#34;:[&#34;right&#34;]},{&#34;label&#34;:[&#34;age&#34;],&#34;name&#34;:[4],&#34;type&#34;:[&#34;dbl&#34;],&#34;align&#34;:[&#34;right&#34;]},{&#34;label&#34;:[&#34;gender&#34;],&#34;name&#34;:[5],&#34;type&#34;:[&#34;dbl&#34;],&#34;align&#34;:[&#34;right&#34;]},{&#34;label&#34;:[&#34;language&#34;],&#34;name&#34;:[6],&#34;type&#34;:[&#34;dbl&#34;],&#34;align&#34;:[&#34;right&#34;]}],&#34;data&#34;:[{&#34;1&#34;:&#34;7&#34;,&#34;2&#34;:&#34;9&#34;,&#34;3&#34;:&#34;9&#34;,&#34;4&#34;:&#34;21&#34;,&#34;5&#34;:&#34;1&#34;,&#34;6&#34;:&#34;1&#34;},{&#34;1&#34;:&#34;9&#34;,&#34;2&#34;:&#34;9&#34;,&#34;3&#34;:&#34;9&#34;,&#34;4&#34;:&#34;38&#34;,&#34;5&#34;:&#34;2&#34;,&#34;6&#34;:&#34;1&#34;},{&#34;1&#34;:&#34;9&#34;,&#34;2&#34;:&#34;9&#34;,&#34;3&#34;:&#34;9&#34;,&#34;4&#34;:&#34;33&#34;,&#34;5&#34;:&#34;2&#34;,&#34;6&#34;:&#34;1&#34;},{&#34;1&#34;:&#34;2&#34;,&#34;2&#34;:&#34;9&#34;,&#34;3&#34;:&#34;9&#34;,&#34;4&#34;:&#34;21&#34;,&#34;5&#34;:&#34;2&#34;,&#34;6&#34;:&#34;1&#34;}],&#34;options&#34;:{&#34;columns&#34;:{&#34;min&#34;:{},&#34;max&#34;:[10]},&#34;rows&#34;:{&#34;min&#34;:[10],&#34;max&#34;:[10]},&#34;pages&#34;:{}}}
  &lt;/script&gt;
&lt;/div&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;new_data %&amp;gt;%
  filter(gender == 1 &amp;amp; language == 1)&lt;/code&gt;&lt;/pre&gt;
&lt;div data-pagedtable=&#34;false&#34;&gt;
&lt;script data-pagedtable-source type=&#34;application/json&#34;&gt;
{&#34;columns&#34;:[{&#34;label&#34;:[&#34;901&#34;],&#34;name&#34;:[1],&#34;type&#34;:[&#34;dbl&#34;],&#34;align&#34;:[&#34;right&#34;]},{&#34;label&#34;:[&#34;902&#34;],&#34;name&#34;:[2],&#34;type&#34;:[&#34;dbl&#34;],&#34;align&#34;:[&#34;right&#34;]},{&#34;label&#34;:[&#34;903&#34;],&#34;name&#34;:[3],&#34;type&#34;:[&#34;dbl&#34;],&#34;align&#34;:[&#34;right&#34;]},{&#34;label&#34;:[&#34;age&#34;],&#34;name&#34;:[4],&#34;type&#34;:[&#34;dbl&#34;],&#34;align&#34;:[&#34;right&#34;]},{&#34;label&#34;:[&#34;gender&#34;],&#34;name&#34;:[5],&#34;type&#34;:[&#34;dbl&#34;],&#34;align&#34;:[&#34;right&#34;]},{&#34;label&#34;:[&#34;language&#34;],&#34;name&#34;:[6],&#34;type&#34;:[&#34;dbl&#34;],&#34;align&#34;:[&#34;right&#34;]}],&#34;data&#34;:[{&#34;1&#34;:&#34;7&#34;,&#34;2&#34;:&#34;9&#34;,&#34;3&#34;:&#34;9&#34;,&#34;4&#34;:&#34;21&#34;,&#34;5&#34;:&#34;1&#34;,&#34;6&#34;:&#34;1&#34;}],&#34;options&#34;:{&#34;columns&#34;:{&#34;min&#34;:{},&#34;max&#34;:[10]},&#34;rows&#34;:{&#34;min&#34;:[10],&#34;max&#34;:[10]},&#34;pages&#34;:{}}}
  &lt;/script&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>List Challenge</title>
      <link>/publication/problem-5/</link>
      <pubDate>Sat, 19 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>/publication/problem-5/</guid>
      <description>
&lt;link href=&#34;/rmarkdown-libs/pagedtable/css/pagedtable.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;script src=&#34;/rmarkdown-libs/pagedtable/js/pagedtable.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;the-problem&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The Problem&lt;/h2&gt;
&lt;p&gt;This is simple, If Names of List are found in List B then Replace:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;a &amp;lt;- list(x = 1, y = TRUE, z = &amp;quot;a&amp;quot;)
b &amp;lt;- list(x = 2, z = &amp;quot;b&amp;quot;)
expected &amp;lt;- list(x = 2, y = TRUE, z = &amp;quot;b&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;the-solution&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The Solution&lt;/h2&gt;
&lt;p&gt;It was hard to think in something simple, because the problem is not as complicated, it is just List is a complicated object to deal with, but I came with this:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;a &amp;lt;- list(x = 1, y = TRUE, z = &amp;quot;a&amp;quot;)
b &amp;lt;- list(x = 2, z = &amp;quot;b&amp;quot;)

val_names &amp;lt;- names(a) %in% names(b) %&amp;gt;% names(a)[.]
a[val_names] &amp;lt;- b[val_names]

a&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## $x
## [1] 2
## 
## $y
## [1] TRUE
## 
## $z
## [1] &amp;quot;b&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Ugly Untied Dataset</title>
      <link>/publication/problem-4/</link>
      <pubDate>Sat, 19 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>/publication/problem-4/</guid>
      <description>
&lt;link href=&#34;/rmarkdown-libs/pagedtable/css/pagedtable.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;script src=&#34;/rmarkdown-libs/pagedtable/js/pagedtable.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;Even though the Data looks messy and an Intruitive solution didn¬¥t pop up inmediately, It was relatively short to fix.&lt;/p&gt;
&lt;div id=&#34;the-problem&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The Problem&lt;/h2&gt;
&lt;p&gt;I want to save some words so I‚Äôll go to the source&lt;/p&gt;
&lt;center&gt;
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;Hey &lt;a href=&#34;https://twitter.com/hashtag/rstats?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#rstats&lt;/a&gt; peeps. I have ~36 tables like this extracted from the LCMM üì¶ results. &lt;br&gt;I need to tidy it. &lt;br&gt;I want 5 rows with the values for intercept and sofa_study_day in individual columns. &lt;br&gt;&lt;br&gt;Suggestions? &lt;a href=&#34;https://t.co/1rFku6T0qt&#34;&gt;pic.twitter.com/1rFku6T0qt&lt;/a&gt;&lt;/p&gt;&amp;mdash; jsonpott (@jsonpott) &lt;a href=&#34;https://twitter.com/jsonpott/status/1185527244569174017?ref_src=twsrc%5Etfw&#34;&gt;October 19, 2019&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;

&lt;/center&gt;
&lt;p&gt;So I just replicated the data and did the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Made data longer eliminating all the NAs that showed up.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Divided into Intercept and sofa_study_day.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Joining both together to obtain the 5 records.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The code looks like this:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data &amp;lt;- tibble::tribble(
  ~Sofa.time.point,     ~Se,   ~Wald, ~p.value,      ~x1,      ~x2,      ~x3,      ~x4,      ~x5,
       &amp;quot;intercept&amp;quot;, 0.12395, -24.333,        0,       NA,       NA,       NA, -3.01592,       NA,
       &amp;quot;intercept&amp;quot;, 0.13165, -40.045,        0,       NA,       NA,       NA,       NA, -5.27211,
       &amp;quot;intercept&amp;quot;, 0.21603,  -7.372,        0,       NA, -1.59253,       NA,       NA,       NA,
       &amp;quot;intercept&amp;quot;, 0.23614,  -5.085,        0,       NA,       NA, -1.20082,       NA,       NA,
       &amp;quot;intercept&amp;quot;,      NA,      NA,        0,        0,       NA,       NA,       NA,       NA,
  &amp;quot;sofa_study_day&amp;quot;, 0.00411, -14.669,        0,       NA,       NA,       NA,       NA, -0.06028,
  &amp;quot;sofa_study_day&amp;quot;, 0.00479, -34.798,        0,       NA,       NA,       NA, -0.16685,       NA,
  &amp;quot;sofa_study_day&amp;quot;, 0.00615, -39.744,        0, -0.24443,       NA,       NA,       NA,       NA,
  &amp;quot;sofa_study_day&amp;quot;, 0.00756,  -9.975,        0,       NA,       NA, -0.07543,       NA,       NA,
  &amp;quot;sofa_study_day&amp;quot;, 0.02224, -24.673,        0,       NA,  -0.5488,       NA,       NA,       NA
  )&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tidy_data &amp;lt;- data %&amp;gt;%
  pivot_longer(
    # keeping columns from &amp;quot;Sofa.time.point&amp;quot; to &amp;quot;p.value&amp;quot;
    -(Sofa.time.point:p.value),
    # transform x columns into just one column
    names_to = &amp;quot;x&amp;quot;,
    # populate with values
    values_to = &amp;quot;values&amp;quot;,
    # dropping NAs
    values_drop_na = TRUE
  )

# &amp;quot;intercept&amp;quot; data
tidy_data %&amp;gt;%
  filter(Sofa.time.point == &amp;quot;intercept&amp;quot;) %&amp;gt;%
  left_join(
    #joined with &amp;quot;sofa_study_day&amp;quot;
    tidy_data %&amp;gt;%
      filter(Sofa.time.point == &amp;quot;sofa_study_day&amp;quot;),
    # joining by &amp;quot;x&amp;quot;
    by = &amp;quot;x&amp;quot;,
    # adding identifiers to columns having the same name
    suffix = c(&amp;quot;.intercept&amp;quot;, &amp;quot;.sofa&amp;quot;)
  )&lt;/code&gt;&lt;/pre&gt;
&lt;div data-pagedtable=&#34;false&#34;&gt;
&lt;script data-pagedtable-source type=&#34;application/json&#34;&gt;
{&#34;columns&#34;:[{&#34;label&#34;:[&#34;Sofa.time.point.intercept&#34;],&#34;name&#34;:[1],&#34;type&#34;:[&#34;chr&#34;],&#34;align&#34;:[&#34;left&#34;]},{&#34;label&#34;:[&#34;Se.intercept&#34;],&#34;name&#34;:[2],&#34;type&#34;:[&#34;dbl&#34;],&#34;align&#34;:[&#34;right&#34;]},{&#34;label&#34;:[&#34;Wald.intercept&#34;],&#34;name&#34;:[3],&#34;type&#34;:[&#34;dbl&#34;],&#34;align&#34;:[&#34;right&#34;]},{&#34;label&#34;:[&#34;p.value.intercept&#34;],&#34;name&#34;:[4],&#34;type&#34;:[&#34;dbl&#34;],&#34;align&#34;:[&#34;right&#34;]},{&#34;label&#34;:[&#34;x&#34;],&#34;name&#34;:[5],&#34;type&#34;:[&#34;chr&#34;],&#34;align&#34;:[&#34;left&#34;]},{&#34;label&#34;:[&#34;values.intercept&#34;],&#34;name&#34;:[6],&#34;type&#34;:[&#34;dbl&#34;],&#34;align&#34;:[&#34;right&#34;]},{&#34;label&#34;:[&#34;Sofa.time.point.sofa&#34;],&#34;name&#34;:[7],&#34;type&#34;:[&#34;chr&#34;],&#34;align&#34;:[&#34;left&#34;]},{&#34;label&#34;:[&#34;Se.sofa&#34;],&#34;name&#34;:[8],&#34;type&#34;:[&#34;dbl&#34;],&#34;align&#34;:[&#34;right&#34;]},{&#34;label&#34;:[&#34;Wald.sofa&#34;],&#34;name&#34;:[9],&#34;type&#34;:[&#34;dbl&#34;],&#34;align&#34;:[&#34;right&#34;]},{&#34;label&#34;:[&#34;p.value.sofa&#34;],&#34;name&#34;:[10],&#34;type&#34;:[&#34;dbl&#34;],&#34;align&#34;:[&#34;right&#34;]},{&#34;label&#34;:[&#34;values.sofa&#34;],&#34;name&#34;:[11],&#34;type&#34;:[&#34;dbl&#34;],&#34;align&#34;:[&#34;right&#34;]}],&#34;data&#34;:[{&#34;1&#34;:&#34;intercept&#34;,&#34;2&#34;:&#34;0.12395&#34;,&#34;3&#34;:&#34;-24.333&#34;,&#34;4&#34;:&#34;0&#34;,&#34;5&#34;:&#34;x4&#34;,&#34;6&#34;:&#34;-3.01592&#34;,&#34;7&#34;:&#34;sofa_study_day&#34;,&#34;8&#34;:&#34;0.00479&#34;,&#34;9&#34;:&#34;-34.798&#34;,&#34;10&#34;:&#34;0&#34;,&#34;11&#34;:&#34;-0.16685&#34;},{&#34;1&#34;:&#34;intercept&#34;,&#34;2&#34;:&#34;0.13165&#34;,&#34;3&#34;:&#34;-40.045&#34;,&#34;4&#34;:&#34;0&#34;,&#34;5&#34;:&#34;x5&#34;,&#34;6&#34;:&#34;-5.27211&#34;,&#34;7&#34;:&#34;sofa_study_day&#34;,&#34;8&#34;:&#34;0.00411&#34;,&#34;9&#34;:&#34;-14.669&#34;,&#34;10&#34;:&#34;0&#34;,&#34;11&#34;:&#34;-0.06028&#34;},{&#34;1&#34;:&#34;intercept&#34;,&#34;2&#34;:&#34;0.21603&#34;,&#34;3&#34;:&#34;-7.372&#34;,&#34;4&#34;:&#34;0&#34;,&#34;5&#34;:&#34;x2&#34;,&#34;6&#34;:&#34;-1.59253&#34;,&#34;7&#34;:&#34;sofa_study_day&#34;,&#34;8&#34;:&#34;0.02224&#34;,&#34;9&#34;:&#34;-24.673&#34;,&#34;10&#34;:&#34;0&#34;,&#34;11&#34;:&#34;-0.54880&#34;},{&#34;1&#34;:&#34;intercept&#34;,&#34;2&#34;:&#34;0.23614&#34;,&#34;3&#34;:&#34;-5.085&#34;,&#34;4&#34;:&#34;0&#34;,&#34;5&#34;:&#34;x3&#34;,&#34;6&#34;:&#34;-1.20082&#34;,&#34;7&#34;:&#34;sofa_study_day&#34;,&#34;8&#34;:&#34;0.00756&#34;,&#34;9&#34;:&#34;-9.975&#34;,&#34;10&#34;:&#34;0&#34;,&#34;11&#34;:&#34;-0.07543&#34;},{&#34;1&#34;:&#34;intercept&#34;,&#34;2&#34;:&#34;NA&#34;,&#34;3&#34;:&#34;NA&#34;,&#34;4&#34;:&#34;0&#34;,&#34;5&#34;:&#34;x1&#34;,&#34;6&#34;:&#34;0.00000&#34;,&#34;7&#34;:&#34;sofa_study_day&#34;,&#34;8&#34;:&#34;0.00615&#34;,&#34;9&#34;:&#34;-39.744&#34;,&#34;10&#34;:&#34;0&#34;,&#34;11&#34;:&#34;-0.24443&#34;}],&#34;options&#34;:{&#34;columns&#34;:{&#34;min&#34;:{},&#34;max&#34;:[10]},&#34;rows&#34;:{&#34;min&#34;:[10],&#34;max&#34;:[10]},&#34;pages&#34;:{}}}
  &lt;/script&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Missing Value Imputation</title>
      <link>/publication/problem-1/</link>
      <pubDate>Wed, 16 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>/publication/problem-1/</guid>
      <description>
&lt;link href=&#34;/rmarkdown-libs/pagedtable/css/pagedtable.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;script src=&#34;/rmarkdown-libs/pagedtable/js/pagedtable.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;Surfing at Stack Overflow I noticed a problem that I found interesting to solve:
The following Data was presented:&lt;/p&gt;
&lt;div id=&#34;the-problem&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The Problem&lt;/h2&gt;
&lt;p&gt;The following Data is presented:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sample &amp;lt;-
  structure(
    list(
      `Country Name` = c(
        &amp;quot;Aruba&amp;quot;,
        &amp;quot;Afghanistan&amp;quot;,
        &amp;quot;Angola&amp;quot;,
        &amp;quot;Albania&amp;quot;,
        &amp;quot;Andorra&amp;quot;,
        &amp;quot;Arab World&amp;quot;,
        &amp;quot;United Arab Emirates&amp;quot;,
        &amp;quot;Argentina&amp;quot;,
        &amp;quot;Armenia&amp;quot;,
        &amp;quot;American Samoa&amp;quot;,
        &amp;quot;Antigua and Barbuda&amp;quot;,
        &amp;quot;Australia&amp;quot;
      ),
      `Country Code` = c(
        &amp;quot;ABW&amp;quot;,
        &amp;quot;AFG&amp;quot;,
        &amp;quot;AGO&amp;quot;,
        &amp;quot;ALB&amp;quot;,
        &amp;quot;AND&amp;quot;,
        &amp;quot;ARB&amp;quot;,
        &amp;quot;ARE&amp;quot;,
        &amp;quot;ARG&amp;quot;,
        &amp;quot;ARM&amp;quot;,
        &amp;quot;ASM&amp;quot;,
        &amp;quot;ATG&amp;quot;,
        &amp;quot;AUS&amp;quot;
      ),
      `2007` = c(
        5.39162036843645,
        8.68057078513406,
        12.2514974459487,
        2.93268248162318,
        NA,
        4.74356585295154,
        NA,
        NA,
        NA,
        NA,
        1.41605259409743,
        NA
      ),
      `2008` = c(
        8.95722105296535,
        26.4186641547444,
        12.4758291326398,
        3.36313757366391,
        NA,
        NA,
        12.2504202448139,
        NA,
        8.94995335353386,
        NA,
        5.33380639820232,
        NA
      ),
      `2009` = c(
        -2.13630037272305,-6.81116108898995,
        13.7302839288409,
        2.23139683475865,
        NA,
        2.92089711805365,
        1.55980098148558,
        NA,
        3.40676682683799,
        NA,
        -0.550159995508869,
        NA
      ),
      `2010` = c(
        2.07773902027782,
        2.1785375238942,
        14.4696564932574,
        3.61538461538463,
        NA,
        3.91106195534027,
        0.879216764156813,
        NA,
        8.17636138473956,
        NA,
        3.3700254022015,
        2.91834002677376
      ),
      `2011` = c(
        4.31633194082721,
        11.8041858089129,
        13.4824679218511,
        3.44283593170005,
        NA,
        4.75316388885632,
        NA,
        NA,
        7.6500080785929,
        NA,
        3.45674967234599,
        3.30385015608744
      ),
      `2012` = c(
        0.627927921638161,
        6.44121280934118,
        10.2779049218839,
        2.03642235579081,
        NA,
        4.61184432206646,
        0.662268900269082,
        NA,
        2.55802007757907,
        NA,
        3.37688044338879,
        1.76278015613193
      ),
      `2013` = c(
        -2.37226328015073,
        7.38577178397857,
        8.77781429332619,
        1.92544399507649,
        NA,
        3.23423783752364,
        1.10111836375706,
        NA,
        5.78966778544654,
        NA,
        1.05949782356168,
        2.44988864142539
      ),
      `2014` = c(
        0.421637771012246,
        4.67399603536339,
        7.28038730361125,
        1.61304235314414,
        NA,
        2.77261158414198,
        2.34626865671643,
        NA,
        2.98130868933673,
        NA,
        1.08944157435363,
        2.48792270531403
      )
    ),
    class = c(&amp;quot;tbl_df&amp;quot;, &amp;quot;tbl&amp;quot;, &amp;quot;data.frame&amp;quot;),
    row.names = c(NA,-12L)
  )

sample&lt;/code&gt;&lt;/pre&gt;
&lt;div data-pagedtable=&#34;false&#34;&gt;
&lt;script data-pagedtable-source type=&#34;application/json&#34;&gt;
{&#34;columns&#34;:[{&#34;label&#34;:[&#34;Country Name&#34;],&#34;name&#34;:[1],&#34;type&#34;:[&#34;chr&#34;],&#34;align&#34;:[&#34;left&#34;]},{&#34;label&#34;:[&#34;Country Code&#34;],&#34;name&#34;:[2],&#34;type&#34;:[&#34;chr&#34;],&#34;align&#34;:[&#34;left&#34;]},{&#34;label&#34;:[&#34;2007&#34;],&#34;name&#34;:[3],&#34;type&#34;:[&#34;dbl&#34;],&#34;align&#34;:[&#34;right&#34;]},{&#34;label&#34;:[&#34;2008&#34;],&#34;name&#34;:[4],&#34;type&#34;:[&#34;dbl&#34;],&#34;align&#34;:[&#34;right&#34;]},{&#34;label&#34;:[&#34;2009&#34;],&#34;name&#34;:[5],&#34;type&#34;:[&#34;dbl&#34;],&#34;align&#34;:[&#34;right&#34;]},{&#34;label&#34;:[&#34;2010&#34;],&#34;name&#34;:[6],&#34;type&#34;:[&#34;dbl&#34;],&#34;align&#34;:[&#34;right&#34;]},{&#34;label&#34;:[&#34;2011&#34;],&#34;name&#34;:[7],&#34;type&#34;:[&#34;dbl&#34;],&#34;align&#34;:[&#34;right&#34;]},{&#34;label&#34;:[&#34;2012&#34;],&#34;name&#34;:[8],&#34;type&#34;:[&#34;dbl&#34;],&#34;align&#34;:[&#34;right&#34;]},{&#34;label&#34;:[&#34;2013&#34;],&#34;name&#34;:[9],&#34;type&#34;:[&#34;dbl&#34;],&#34;align&#34;:[&#34;right&#34;]},{&#34;label&#34;:[&#34;2014&#34;],&#34;name&#34;:[10],&#34;type&#34;:[&#34;dbl&#34;],&#34;align&#34;:[&#34;right&#34;]}],&#34;data&#34;:[{&#34;1&#34;:&#34;Aruba&#34;,&#34;2&#34;:&#34;ABW&#34;,&#34;3&#34;:&#34;5.391620&#34;,&#34;4&#34;:&#34;8.957221&#34;,&#34;5&#34;:&#34;-2.136300&#34;,&#34;6&#34;:&#34;2.0777390&#34;,&#34;7&#34;:&#34;4.316332&#34;,&#34;8&#34;:&#34;0.6279279&#34;,&#34;9&#34;:&#34;-2.372263&#34;,&#34;10&#34;:&#34;0.4216378&#34;},{&#34;1&#34;:&#34;Afghanistan&#34;,&#34;2&#34;:&#34;AFG&#34;,&#34;3&#34;:&#34;8.680571&#34;,&#34;4&#34;:&#34;26.418664&#34;,&#34;5&#34;:&#34;-6.811161&#34;,&#34;6&#34;:&#34;2.1785375&#34;,&#34;7&#34;:&#34;11.804186&#34;,&#34;8&#34;:&#34;6.4412128&#34;,&#34;9&#34;:&#34;7.385772&#34;,&#34;10&#34;:&#34;4.6739960&#34;},{&#34;1&#34;:&#34;Angola&#34;,&#34;2&#34;:&#34;AGO&#34;,&#34;3&#34;:&#34;12.251497&#34;,&#34;4&#34;:&#34;12.475829&#34;,&#34;5&#34;:&#34;13.730284&#34;,&#34;6&#34;:&#34;14.4696565&#34;,&#34;7&#34;:&#34;13.482468&#34;,&#34;8&#34;:&#34;10.2779049&#34;,&#34;9&#34;:&#34;8.777814&#34;,&#34;10&#34;:&#34;7.2803873&#34;},{&#34;1&#34;:&#34;Albania&#34;,&#34;2&#34;:&#34;ALB&#34;,&#34;3&#34;:&#34;2.932682&#34;,&#34;4&#34;:&#34;3.363138&#34;,&#34;5&#34;:&#34;2.231397&#34;,&#34;6&#34;:&#34;3.6153846&#34;,&#34;7&#34;:&#34;3.442836&#34;,&#34;8&#34;:&#34;2.0364224&#34;,&#34;9&#34;:&#34;1.925444&#34;,&#34;10&#34;:&#34;1.6130424&#34;},{&#34;1&#34;:&#34;Andorra&#34;,&#34;2&#34;:&#34;AND&#34;,&#34;3&#34;:&#34;NA&#34;,&#34;4&#34;:&#34;NA&#34;,&#34;5&#34;:&#34;NA&#34;,&#34;6&#34;:&#34;NA&#34;,&#34;7&#34;:&#34;NA&#34;,&#34;8&#34;:&#34;NA&#34;,&#34;9&#34;:&#34;NA&#34;,&#34;10&#34;:&#34;NA&#34;},{&#34;1&#34;:&#34;Arab World&#34;,&#34;2&#34;:&#34;ARB&#34;,&#34;3&#34;:&#34;4.743566&#34;,&#34;4&#34;:&#34;NA&#34;,&#34;5&#34;:&#34;2.920897&#34;,&#34;6&#34;:&#34;3.9110620&#34;,&#34;7&#34;:&#34;4.753164&#34;,&#34;8&#34;:&#34;4.6118443&#34;,&#34;9&#34;:&#34;3.234238&#34;,&#34;10&#34;:&#34;2.7726116&#34;},{&#34;1&#34;:&#34;United Arab Emirates&#34;,&#34;2&#34;:&#34;ARE&#34;,&#34;3&#34;:&#34;NA&#34;,&#34;4&#34;:&#34;12.250420&#34;,&#34;5&#34;:&#34;1.559801&#34;,&#34;6&#34;:&#34;0.8792168&#34;,&#34;7&#34;:&#34;NA&#34;,&#34;8&#34;:&#34;0.6622689&#34;,&#34;9&#34;:&#34;1.101118&#34;,&#34;10&#34;:&#34;2.3462687&#34;},{&#34;1&#34;:&#34;Argentina&#34;,&#34;2&#34;:&#34;ARG&#34;,&#34;3&#34;:&#34;NA&#34;,&#34;4&#34;:&#34;NA&#34;,&#34;5&#34;:&#34;NA&#34;,&#34;6&#34;:&#34;NA&#34;,&#34;7&#34;:&#34;NA&#34;,&#34;8&#34;:&#34;NA&#34;,&#34;9&#34;:&#34;NA&#34;,&#34;10&#34;:&#34;NA&#34;},{&#34;1&#34;:&#34;Armenia&#34;,&#34;2&#34;:&#34;ARM&#34;,&#34;3&#34;:&#34;NA&#34;,&#34;4&#34;:&#34;8.949953&#34;,&#34;5&#34;:&#34;3.406767&#34;,&#34;6&#34;:&#34;8.1763614&#34;,&#34;7&#34;:&#34;7.650008&#34;,&#34;8&#34;:&#34;2.5580201&#34;,&#34;9&#34;:&#34;5.789668&#34;,&#34;10&#34;:&#34;2.9813087&#34;},{&#34;1&#34;:&#34;American Samoa&#34;,&#34;2&#34;:&#34;ASM&#34;,&#34;3&#34;:&#34;NA&#34;,&#34;4&#34;:&#34;NA&#34;,&#34;5&#34;:&#34;NA&#34;,&#34;6&#34;:&#34;NA&#34;,&#34;7&#34;:&#34;NA&#34;,&#34;8&#34;:&#34;NA&#34;,&#34;9&#34;:&#34;NA&#34;,&#34;10&#34;:&#34;NA&#34;},{&#34;1&#34;:&#34;Antigua and Barbuda&#34;,&#34;2&#34;:&#34;ATG&#34;,&#34;3&#34;:&#34;1.416053&#34;,&#34;4&#34;:&#34;5.333806&#34;,&#34;5&#34;:&#34;-0.550160&#34;,&#34;6&#34;:&#34;3.3700254&#34;,&#34;7&#34;:&#34;3.456750&#34;,&#34;8&#34;:&#34;3.3768804&#34;,&#34;9&#34;:&#34;1.059498&#34;,&#34;10&#34;:&#34;1.0894416&#34;},{&#34;1&#34;:&#34;Australia&#34;,&#34;2&#34;:&#34;AUS&#34;,&#34;3&#34;:&#34;NA&#34;,&#34;4&#34;:&#34;NA&#34;,&#34;5&#34;:&#34;NA&#34;,&#34;6&#34;:&#34;2.9183400&#34;,&#34;7&#34;:&#34;3.303850&#34;,&#34;8&#34;:&#34;1.7627802&#34;,&#34;9&#34;:&#34;2.449889&#34;,&#34;10&#34;:&#34;2.4879227&#34;}],&#34;options&#34;:{&#34;columns&#34;:{&#34;min&#34;:{},&#34;max&#34;:[10]},&#34;rows&#34;:{&#34;min&#34;:[10],&#34;max&#34;:[10]},&#34;pages&#34;:{}}}
  &lt;/script&gt;
&lt;/div&gt;
&lt;p&gt;The idea is to input Missing Values following some rules:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;Some countries have NAs for all 8 years (columns 3:10), and in that case I want to replace all NAs with the column mean.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Other countries only have NAs in some columns, in which case I want to replace NA with the previous year‚Äôs value.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The final condition is that, if the NA is in the first year (2007), I want to replace it with the 2007 column mean instead of the next year (2008 was the financial crisis so all the inflation rates went nuts).&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Of course this can be easily programmed using Regular Programming Rules using For loops and If Statements, but the idea is to do it in a tidy way using the Tidyverse.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(dplyr, warn.conflicts = FALSE)
library(tidyr)
library(janitor)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Attaching package: &amp;#39;janitor&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## The following objects are masked from &amp;#39;package:stats&amp;#39;:
## 
##     chisq.test, fisher.test&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Getting the Column Means to Replace according to Condition 1 and 3. 
(replacement &amp;lt;- sample %&amp;gt;%
    select_if(is.numeric) %&amp;gt;%
    summarize_all( ~ mean(., na.rm = TRUE)) %&amp;gt;%
    #Transformed to List since it is a requirement for tidyr::replace_na()
    as.list())&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## $`2007`
## [1] 5.902665
## 
## $`2008`
## [1] 11.107
## 
## $`2009`
## [1] 1.793941
## 
## $`2010`
## [1] 4.621814
## 
## $`2011`
## [1] 6.526199
## 
## $`2012`
## [1] 3.595029
## 
## $`2013`
## [1] 3.261242
## 
## $`2014`
## [1] 2.851846&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;the-solution&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The solution&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sample %&amp;gt;%
  pivot_longer(`2007`:`2014`, names_to = &amp;quot;year&amp;quot;, values_to = &amp;quot;int_rate&amp;quot;) %&amp;gt;%
  group_by(`Country Name`) %&amp;gt;%
  summarize(na_num = is.na(int_rate) %&amp;gt;% sum) %&amp;gt;%
  #Joining the number of NAs na_num as a new column
  left_join(sample, by = &amp;quot;Country Name&amp;quot;) %&amp;gt;%
  #Replacing 2007 missing as a first value. Condition 3.
  mutate(`2007` = if_else(between(na_num, 1, 7) &amp;amp;
                            is.na(`2007`), replacement[[1]] , `2007`)) %&amp;gt;%
  #Making dataset wider 
  pivot_longer(`2007`:`2014`, names_to = &amp;quot;year&amp;quot;, values_to = &amp;quot;int_rate&amp;quot;) %&amp;gt;%
  group_by(`Country Name`) %&amp;gt;%
  #Using fill to impute NAs with the previous one. Condition 2.
  fill(int_rate) %&amp;gt;%
  pivot_wider(names_from = year, values_from = int_rate) %&amp;gt;%
  #Replacing Values when all values are missing. Condition 1.
  replace_na(replace = replacement) &lt;/code&gt;&lt;/pre&gt;
&lt;div data-pagedtable=&#34;false&#34;&gt;
&lt;script data-pagedtable-source type=&#34;application/json&#34;&gt;
{&#34;columns&#34;:[{&#34;label&#34;:[&#34;Country Name&#34;],&#34;name&#34;:[1],&#34;type&#34;:[&#34;chr&#34;],&#34;align&#34;:[&#34;left&#34;]},{&#34;label&#34;:[&#34;na_num&#34;],&#34;name&#34;:[2],&#34;type&#34;:[&#34;int&#34;],&#34;align&#34;:[&#34;right&#34;]},{&#34;label&#34;:[&#34;Country Code&#34;],&#34;name&#34;:[3],&#34;type&#34;:[&#34;chr&#34;],&#34;align&#34;:[&#34;left&#34;]},{&#34;label&#34;:[&#34;2007&#34;],&#34;name&#34;:[4],&#34;type&#34;:[&#34;dbl&#34;],&#34;align&#34;:[&#34;right&#34;]},{&#34;label&#34;:[&#34;2008&#34;],&#34;name&#34;:[5],&#34;type&#34;:[&#34;dbl&#34;],&#34;align&#34;:[&#34;right&#34;]},{&#34;label&#34;:[&#34;2009&#34;],&#34;name&#34;:[6],&#34;type&#34;:[&#34;dbl&#34;],&#34;align&#34;:[&#34;right&#34;]},{&#34;label&#34;:[&#34;2010&#34;],&#34;name&#34;:[7],&#34;type&#34;:[&#34;dbl&#34;],&#34;align&#34;:[&#34;right&#34;]},{&#34;label&#34;:[&#34;2011&#34;],&#34;name&#34;:[8],&#34;type&#34;:[&#34;dbl&#34;],&#34;align&#34;:[&#34;right&#34;]},{&#34;label&#34;:[&#34;2012&#34;],&#34;name&#34;:[9],&#34;type&#34;:[&#34;dbl&#34;],&#34;align&#34;:[&#34;right&#34;]},{&#34;label&#34;:[&#34;2013&#34;],&#34;name&#34;:[10],&#34;type&#34;:[&#34;dbl&#34;],&#34;align&#34;:[&#34;right&#34;]},{&#34;label&#34;:[&#34;2014&#34;],&#34;name&#34;:[11],&#34;type&#34;:[&#34;dbl&#34;],&#34;align&#34;:[&#34;right&#34;]}],&#34;data&#34;:[{&#34;1&#34;:&#34;Afghanistan&#34;,&#34;2&#34;:&#34;0&#34;,&#34;3&#34;:&#34;AFG&#34;,&#34;4&#34;:&#34;8.680571&#34;,&#34;5&#34;:&#34;26.418664&#34;,&#34;6&#34;:&#34;-6.811161&#34;,&#34;7&#34;:&#34;2.1785375&#34;,&#34;8&#34;:&#34;11.8041858&#34;,&#34;9&#34;:&#34;6.4412128&#34;,&#34;10&#34;:&#34;7.385772&#34;,&#34;11&#34;:&#34;4.6739960&#34;},{&#34;1&#34;:&#34;Albania&#34;,&#34;2&#34;:&#34;0&#34;,&#34;3&#34;:&#34;ALB&#34;,&#34;4&#34;:&#34;2.932682&#34;,&#34;5&#34;:&#34;3.363138&#34;,&#34;6&#34;:&#34;2.231397&#34;,&#34;7&#34;:&#34;3.6153846&#34;,&#34;8&#34;:&#34;3.4428359&#34;,&#34;9&#34;:&#34;2.0364224&#34;,&#34;10&#34;:&#34;1.925444&#34;,&#34;11&#34;:&#34;1.6130424&#34;},{&#34;1&#34;:&#34;American Samoa&#34;,&#34;2&#34;:&#34;8&#34;,&#34;3&#34;:&#34;ASM&#34;,&#34;4&#34;:&#34;5.902665&#34;,&#34;5&#34;:&#34;11.107005&#34;,&#34;6&#34;:&#34;1.793941&#34;,&#34;7&#34;:&#34;4.6218137&#34;,&#34;8&#34;:&#34;6.5261992&#34;,&#34;9&#34;:&#34;3.5950291&#34;,&#34;10&#34;:&#34;3.261242&#34;,&#34;11&#34;:&#34;2.8518463&#34;},{&#34;1&#34;:&#34;Andorra&#34;,&#34;2&#34;:&#34;8&#34;,&#34;3&#34;:&#34;AND&#34;,&#34;4&#34;:&#34;5.902665&#34;,&#34;5&#34;:&#34;11.107005&#34;,&#34;6&#34;:&#34;1.793941&#34;,&#34;7&#34;:&#34;4.6218137&#34;,&#34;8&#34;:&#34;6.5261992&#34;,&#34;9&#34;:&#34;3.5950291&#34;,&#34;10&#34;:&#34;3.261242&#34;,&#34;11&#34;:&#34;2.8518463&#34;},{&#34;1&#34;:&#34;Angola&#34;,&#34;2&#34;:&#34;0&#34;,&#34;3&#34;:&#34;AGO&#34;,&#34;4&#34;:&#34;12.251497&#34;,&#34;5&#34;:&#34;12.475829&#34;,&#34;6&#34;:&#34;13.730284&#34;,&#34;7&#34;:&#34;14.4696565&#34;,&#34;8&#34;:&#34;13.4824679&#34;,&#34;9&#34;:&#34;10.2779049&#34;,&#34;10&#34;:&#34;8.777814&#34;,&#34;11&#34;:&#34;7.2803873&#34;},{&#34;1&#34;:&#34;Antigua and Barbuda&#34;,&#34;2&#34;:&#34;0&#34;,&#34;3&#34;:&#34;ATG&#34;,&#34;4&#34;:&#34;1.416053&#34;,&#34;5&#34;:&#34;5.333806&#34;,&#34;6&#34;:&#34;-0.550160&#34;,&#34;7&#34;:&#34;3.3700254&#34;,&#34;8&#34;:&#34;3.4567497&#34;,&#34;9&#34;:&#34;3.3768804&#34;,&#34;10&#34;:&#34;1.059498&#34;,&#34;11&#34;:&#34;1.0894416&#34;},{&#34;1&#34;:&#34;Arab World&#34;,&#34;2&#34;:&#34;1&#34;,&#34;3&#34;:&#34;ARB&#34;,&#34;4&#34;:&#34;4.743566&#34;,&#34;5&#34;:&#34;4.743566&#34;,&#34;6&#34;:&#34;2.920897&#34;,&#34;7&#34;:&#34;3.9110620&#34;,&#34;8&#34;:&#34;4.7531639&#34;,&#34;9&#34;:&#34;4.6118443&#34;,&#34;10&#34;:&#34;3.234238&#34;,&#34;11&#34;:&#34;2.7726116&#34;},{&#34;1&#34;:&#34;Argentina&#34;,&#34;2&#34;:&#34;8&#34;,&#34;3&#34;:&#34;ARG&#34;,&#34;4&#34;:&#34;5.902665&#34;,&#34;5&#34;:&#34;11.107005&#34;,&#34;6&#34;:&#34;1.793941&#34;,&#34;7&#34;:&#34;4.6218137&#34;,&#34;8&#34;:&#34;6.5261992&#34;,&#34;9&#34;:&#34;3.5950291&#34;,&#34;10&#34;:&#34;3.261242&#34;,&#34;11&#34;:&#34;2.8518463&#34;},{&#34;1&#34;:&#34;Armenia&#34;,&#34;2&#34;:&#34;1&#34;,&#34;3&#34;:&#34;ARM&#34;,&#34;4&#34;:&#34;5.902665&#34;,&#34;5&#34;:&#34;8.949953&#34;,&#34;6&#34;:&#34;3.406767&#34;,&#34;7&#34;:&#34;8.1763614&#34;,&#34;8&#34;:&#34;7.6500081&#34;,&#34;9&#34;:&#34;2.5580201&#34;,&#34;10&#34;:&#34;5.789668&#34;,&#34;11&#34;:&#34;2.9813087&#34;},{&#34;1&#34;:&#34;Aruba&#34;,&#34;2&#34;:&#34;0&#34;,&#34;3&#34;:&#34;ABW&#34;,&#34;4&#34;:&#34;5.391620&#34;,&#34;5&#34;:&#34;8.957221&#34;,&#34;6&#34;:&#34;-2.136300&#34;,&#34;7&#34;:&#34;2.0777390&#34;,&#34;8&#34;:&#34;4.3163319&#34;,&#34;9&#34;:&#34;0.6279279&#34;,&#34;10&#34;:&#34;-2.372263&#34;,&#34;11&#34;:&#34;0.4216378&#34;},{&#34;1&#34;:&#34;Australia&#34;,&#34;2&#34;:&#34;3&#34;,&#34;3&#34;:&#34;AUS&#34;,&#34;4&#34;:&#34;5.902665&#34;,&#34;5&#34;:&#34;5.902665&#34;,&#34;6&#34;:&#34;5.902665&#34;,&#34;7&#34;:&#34;2.9183400&#34;,&#34;8&#34;:&#34;3.3038502&#34;,&#34;9&#34;:&#34;1.7627802&#34;,&#34;10&#34;:&#34;2.449889&#34;,&#34;11&#34;:&#34;2.4879227&#34;},{&#34;1&#34;:&#34;United Arab Emirates&#34;,&#34;2&#34;:&#34;2&#34;,&#34;3&#34;:&#34;ARE&#34;,&#34;4&#34;:&#34;5.902665&#34;,&#34;5&#34;:&#34;12.250420&#34;,&#34;6&#34;:&#34;1.559801&#34;,&#34;7&#34;:&#34;0.8792168&#34;,&#34;8&#34;:&#34;0.8792168&#34;,&#34;9&#34;:&#34;0.6622689&#34;,&#34;10&#34;:&#34;1.101118&#34;,&#34;11&#34;:&#34;2.3462687&#34;}],&#34;options&#34;:{&#34;columns&#34;:{&#34;min&#34;:{},&#34;max&#34;:[10]},&#34;rows&#34;:{&#34;min&#34;:[10],&#34;max&#34;:[10]},&#34;pages&#34;:{}}}
  &lt;/script&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Tidy Evaluation</title>
      <link>/publication/problem-2/</link>
      <pubDate>Wed, 16 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>/publication/problem-2/</guid>
      <description>
&lt;link href=&#34;/rmarkdown-libs/pagedtable/css/pagedtable.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;script src=&#34;/rmarkdown-libs/pagedtable/js/pagedtable.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;Navigating Twitter I found this other Problem:&lt;/p&gt;
&lt;div id=&#34;the-problem&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The Problem&lt;/h2&gt;
&lt;p&gt;The following dummy_function is presented:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(dplyr)
#&amp;gt; 
a &amp;lt;- sample(letters[1:5], 500, rep = TRUE)
b &amp;lt;- sample(1:10, 500, rep = TRUE)
df1 &amp;lt;- data.frame(a, b)
 
dummy_function &amp;lt;- function(data, var1, var2){
  # Creating summary statistics
  df &amp;lt;- data %&amp;gt;%
    group_by(var1, var2) %&amp;gt;%
    summarise(n=n()) %&amp;gt;%
    group_by(var1) %&amp;gt;%
    mutate(perc=100*n/sum(n))
    
  df
}
dummy_function(df1, a, b)
#&amp;gt; Error: Column `var1` is unknown&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;
Created by the &lt;a href=&#34;https://reprex.tidyverse.org&#34;&gt;reprex package&lt;/a&gt; (v0.3.0)
&lt;/p&gt;
&lt;p&gt;This is a typical problem caused by one of the coolest things provided by the tidyverse: the Non-Standard Evaluation.&lt;/p&gt;
&lt;p&gt;Non-Standard Evaluation is the ability that some R functions have (mainly in the tidyverse and all the packages following a tidy approach) when you can pass a variable within the data without quoting:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;iris %&amp;gt;% 
  select(Species) %&amp;gt;%
  head(10)&lt;/code&gt;&lt;/pre&gt;
&lt;div data-pagedtable=&#34;false&#34;&gt;
&lt;script data-pagedtable-source type=&#34;application/json&#34;&gt;
{&#34;columns&#34;:[{&#34;label&#34;:[&#34;&#34;],&#34;name&#34;:[&#34;_rn_&#34;],&#34;type&#34;:[&#34;&#34;],&#34;align&#34;:[&#34;left&#34;]},{&#34;label&#34;:[&#34;Species&#34;],&#34;name&#34;:[1],&#34;type&#34;:[&#34;fctr&#34;],&#34;align&#34;:[&#34;left&#34;]}],&#34;data&#34;:[{&#34;1&#34;:&#34;setosa&#34;,&#34;_rn_&#34;:&#34;1&#34;},{&#34;1&#34;:&#34;setosa&#34;,&#34;_rn_&#34;:&#34;2&#34;},{&#34;1&#34;:&#34;setosa&#34;,&#34;_rn_&#34;:&#34;3&#34;},{&#34;1&#34;:&#34;setosa&#34;,&#34;_rn_&#34;:&#34;4&#34;},{&#34;1&#34;:&#34;setosa&#34;,&#34;_rn_&#34;:&#34;5&#34;},{&#34;1&#34;:&#34;setosa&#34;,&#34;_rn_&#34;:&#34;6&#34;},{&#34;1&#34;:&#34;setosa&#34;,&#34;_rn_&#34;:&#34;7&#34;},{&#34;1&#34;:&#34;setosa&#34;,&#34;_rn_&#34;:&#34;8&#34;},{&#34;1&#34;:&#34;setosa&#34;,&#34;_rn_&#34;:&#34;9&#34;},{&#34;1&#34;:&#34;setosa&#34;,&#34;_rn_&#34;:&#34;10&#34;}],&#34;options&#34;:{&#34;columns&#34;:{&#34;min&#34;:{},&#34;max&#34;:[10]},&#34;rows&#34;:{&#34;min&#34;:[10],&#34;max&#34;:[10]},&#34;pages&#34;:{}}}
  &lt;/script&gt;
&lt;/div&gt;
&lt;p&gt;As you may see, you don¬¥t need to quote Species, but R is not recognizing Species as an R object but as an existing variable within iris dataset. If you would like to do the same thing using ‚Äú&lt;em&gt;Standard Evaluation&lt;/em&gt;‚Äù you¬¥d have to code something like this:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(iris[&amp;quot;Species&amp;quot;], 10)&lt;/code&gt;&lt;/pre&gt;
&lt;div data-pagedtable=&#34;false&#34;&gt;
&lt;script data-pagedtable-source type=&#34;application/json&#34;&gt;
{&#34;columns&#34;:[{&#34;label&#34;:[&#34;&#34;],&#34;name&#34;:[&#34;_rn_&#34;],&#34;type&#34;:[&#34;&#34;],&#34;align&#34;:[&#34;left&#34;]},{&#34;label&#34;:[&#34;Species&#34;],&#34;name&#34;:[1],&#34;type&#34;:[&#34;fctr&#34;],&#34;align&#34;:[&#34;left&#34;]}],&#34;data&#34;:[{&#34;1&#34;:&#34;setosa&#34;,&#34;_rn_&#34;:&#34;1&#34;},{&#34;1&#34;:&#34;setosa&#34;,&#34;_rn_&#34;:&#34;2&#34;},{&#34;1&#34;:&#34;setosa&#34;,&#34;_rn_&#34;:&#34;3&#34;},{&#34;1&#34;:&#34;setosa&#34;,&#34;_rn_&#34;:&#34;4&#34;},{&#34;1&#34;:&#34;setosa&#34;,&#34;_rn_&#34;:&#34;5&#34;},{&#34;1&#34;:&#34;setosa&#34;,&#34;_rn_&#34;:&#34;6&#34;},{&#34;1&#34;:&#34;setosa&#34;,&#34;_rn_&#34;:&#34;7&#34;},{&#34;1&#34;:&#34;setosa&#34;,&#34;_rn_&#34;:&#34;8&#34;},{&#34;1&#34;:&#34;setosa&#34;,&#34;_rn_&#34;:&#34;9&#34;},{&#34;1&#34;:&#34;setosa&#34;,&#34;_rn_&#34;:&#34;10&#34;}],&#34;options&#34;:{&#34;columns&#34;:{&#34;min&#34;:{},&#34;max&#34;:[10]},&#34;rows&#34;:{&#34;min&#34;:[10],&#34;max&#34;:[10]},&#34;pages&#34;:{}}}
  &lt;/script&gt;
&lt;/div&gt;
&lt;p&gt;In this case you see Species is not an object but a quoted string that is passed as the Variable name for object Iris.&lt;/p&gt;
&lt;p&gt;The error then pops up because in the dummy_function() you have group_by() that uses NSE having var1, var2 as arguments and var1 and var2 objects are not variables of data. What you actually want is to pass var1 and var2 values as the grouping variables.&lt;/p&gt;
&lt;p&gt;Definitely NSE is a great addition and saves typing, but when it comes to create functions it used to be a nightmare. rlang package handled this using something called quosures, and the bang-bang operator. If you want to know about this Hadley teaches it in 5 minutes:&lt;/p&gt;
&lt;center&gt;

&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//www.youtube.com/embed/nERXS3ssntw&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;/center&gt;
&lt;/div&gt;
&lt;div id=&#34;the-solution&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The solution&lt;/h2&gt;
&lt;p&gt;Fortunately, Hadley‚Äôs explanation is helpful to understand the problem but the solution now is super easy with the new version of rlang. You just need to wrap var1 and var2 in the new curly-curly operator to embrace the values of var1 and var2 and pass them along the group_by() function.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;a &amp;lt;- sample(letters[1:5], 500, rep = TRUE)
b &amp;lt;- sample(1:10, 500, rep = TRUE)
df1 &amp;lt;- data.frame(a, b)

library(rlang)
dummy_function &amp;lt;- function(data, var1, var2){
  # Creating summary statistics
  df &amp;lt;- data %&amp;gt;%
    group_by({{var1}}, {{var2}}) %&amp;gt;%
    summarise(n=n()) %&amp;gt;%
    group_by({{var1}}) %&amp;gt;%
    mutate(perc=100*n/sum(n))
  
  df
}
dummy_function(df1, a, b)&lt;/code&gt;&lt;/pre&gt;
&lt;div data-pagedtable=&#34;false&#34;&gt;
&lt;script data-pagedtable-source type=&#34;application/json&#34;&gt;
{&#34;columns&#34;:[{&#34;label&#34;:[&#34;a&#34;],&#34;name&#34;:[1],&#34;type&#34;:[&#34;fctr&#34;],&#34;align&#34;:[&#34;left&#34;]},{&#34;label&#34;:[&#34;b&#34;],&#34;name&#34;:[2],&#34;type&#34;:[&#34;int&#34;],&#34;align&#34;:[&#34;right&#34;]},{&#34;label&#34;:[&#34;n&#34;],&#34;name&#34;:[3],&#34;type&#34;:[&#34;int&#34;],&#34;align&#34;:[&#34;right&#34;]},{&#34;label&#34;:[&#34;perc&#34;],&#34;name&#34;:[4],&#34;type&#34;:[&#34;dbl&#34;],&#34;align&#34;:[&#34;right&#34;]}],&#34;data&#34;:[{&#34;1&#34;:&#34;a&#34;,&#34;2&#34;:&#34;1&#34;,&#34;3&#34;:&#34;13&#34;,&#34;4&#34;:&#34;11.403509&#34;},{&#34;1&#34;:&#34;a&#34;,&#34;2&#34;:&#34;2&#34;,&#34;3&#34;:&#34;14&#34;,&#34;4&#34;:&#34;12.280702&#34;},{&#34;1&#34;:&#34;a&#34;,&#34;2&#34;:&#34;3&#34;,&#34;3&#34;:&#34;16&#34;,&#34;4&#34;:&#34;14.035088&#34;},{&#34;1&#34;:&#34;a&#34;,&#34;2&#34;:&#34;4&#34;,&#34;3&#34;:&#34;3&#34;,&#34;4&#34;:&#34;2.631579&#34;},{&#34;1&#34;:&#34;a&#34;,&#34;2&#34;:&#34;5&#34;,&#34;3&#34;:&#34;10&#34;,&#34;4&#34;:&#34;8.771930&#34;},{&#34;1&#34;:&#34;a&#34;,&#34;2&#34;:&#34;6&#34;,&#34;3&#34;:&#34;8&#34;,&#34;4&#34;:&#34;7.017544&#34;},{&#34;1&#34;:&#34;a&#34;,&#34;2&#34;:&#34;7&#34;,&#34;3&#34;:&#34;13&#34;,&#34;4&#34;:&#34;11.403509&#34;},{&#34;1&#34;:&#34;a&#34;,&#34;2&#34;:&#34;8&#34;,&#34;3&#34;:&#34;15&#34;,&#34;4&#34;:&#34;13.157895&#34;},{&#34;1&#34;:&#34;a&#34;,&#34;2&#34;:&#34;9&#34;,&#34;3&#34;:&#34;14&#34;,&#34;4&#34;:&#34;12.280702&#34;},{&#34;1&#34;:&#34;a&#34;,&#34;2&#34;:&#34;10&#34;,&#34;3&#34;:&#34;8&#34;,&#34;4&#34;:&#34;7.017544&#34;},{&#34;1&#34;:&#34;b&#34;,&#34;2&#34;:&#34;1&#34;,&#34;3&#34;:&#34;10&#34;,&#34;4&#34;:&#34;10.416667&#34;},{&#34;1&#34;:&#34;b&#34;,&#34;2&#34;:&#34;2&#34;,&#34;3&#34;:&#34;8&#34;,&#34;4&#34;:&#34;8.333333&#34;},{&#34;1&#34;:&#34;b&#34;,&#34;2&#34;:&#34;3&#34;,&#34;3&#34;:&#34;5&#34;,&#34;4&#34;:&#34;5.208333&#34;},{&#34;1&#34;:&#34;b&#34;,&#34;2&#34;:&#34;4&#34;,&#34;3&#34;:&#34;8&#34;,&#34;4&#34;:&#34;8.333333&#34;},{&#34;1&#34;:&#34;b&#34;,&#34;2&#34;:&#34;5&#34;,&#34;3&#34;:&#34;9&#34;,&#34;4&#34;:&#34;9.375000&#34;},{&#34;1&#34;:&#34;b&#34;,&#34;2&#34;:&#34;6&#34;,&#34;3&#34;:&#34;12&#34;,&#34;4&#34;:&#34;12.500000&#34;},{&#34;1&#34;:&#34;b&#34;,&#34;2&#34;:&#34;7&#34;,&#34;3&#34;:&#34;11&#34;,&#34;4&#34;:&#34;11.458333&#34;},{&#34;1&#34;:&#34;b&#34;,&#34;2&#34;:&#34;8&#34;,&#34;3&#34;:&#34;12&#34;,&#34;4&#34;:&#34;12.500000&#34;},{&#34;1&#34;:&#34;b&#34;,&#34;2&#34;:&#34;9&#34;,&#34;3&#34;:&#34;9&#34;,&#34;4&#34;:&#34;9.375000&#34;},{&#34;1&#34;:&#34;b&#34;,&#34;2&#34;:&#34;10&#34;,&#34;3&#34;:&#34;12&#34;,&#34;4&#34;:&#34;12.500000&#34;},{&#34;1&#34;:&#34;c&#34;,&#34;2&#34;:&#34;1&#34;,&#34;3&#34;:&#34;9&#34;,&#34;4&#34;:&#34;9.890110&#34;},{&#34;1&#34;:&#34;c&#34;,&#34;2&#34;:&#34;2&#34;,&#34;3&#34;:&#34;7&#34;,&#34;4&#34;:&#34;7.692308&#34;},{&#34;1&#34;:&#34;c&#34;,&#34;2&#34;:&#34;3&#34;,&#34;3&#34;:&#34;10&#34;,&#34;4&#34;:&#34;10.989011&#34;},{&#34;1&#34;:&#34;c&#34;,&#34;2&#34;:&#34;4&#34;,&#34;3&#34;:&#34;9&#34;,&#34;4&#34;:&#34;9.890110&#34;},{&#34;1&#34;:&#34;c&#34;,&#34;2&#34;:&#34;5&#34;,&#34;3&#34;:&#34;11&#34;,&#34;4&#34;:&#34;12.087912&#34;},{&#34;1&#34;:&#34;c&#34;,&#34;2&#34;:&#34;6&#34;,&#34;3&#34;:&#34;10&#34;,&#34;4&#34;:&#34;10.989011&#34;},{&#34;1&#34;:&#34;c&#34;,&#34;2&#34;:&#34;7&#34;,&#34;3&#34;:&#34;9&#34;,&#34;4&#34;:&#34;9.890110&#34;},{&#34;1&#34;:&#34;c&#34;,&#34;2&#34;:&#34;8&#34;,&#34;3&#34;:&#34;8&#34;,&#34;4&#34;:&#34;8.791209&#34;},{&#34;1&#34;:&#34;c&#34;,&#34;2&#34;:&#34;9&#34;,&#34;3&#34;:&#34;7&#34;,&#34;4&#34;:&#34;7.692308&#34;},{&#34;1&#34;:&#34;c&#34;,&#34;2&#34;:&#34;10&#34;,&#34;3&#34;:&#34;11&#34;,&#34;4&#34;:&#34;12.087912&#34;},{&#34;1&#34;:&#34;d&#34;,&#34;2&#34;:&#34;1&#34;,&#34;3&#34;:&#34;10&#34;,&#34;4&#34;:&#34;10.869565&#34;},{&#34;1&#34;:&#34;d&#34;,&#34;2&#34;:&#34;2&#34;,&#34;3&#34;:&#34;14&#34;,&#34;4&#34;:&#34;15.217391&#34;},{&#34;1&#34;:&#34;d&#34;,&#34;2&#34;:&#34;3&#34;,&#34;3&#34;:&#34;10&#34;,&#34;4&#34;:&#34;10.869565&#34;},{&#34;1&#34;:&#34;d&#34;,&#34;2&#34;:&#34;4&#34;,&#34;3&#34;:&#34;12&#34;,&#34;4&#34;:&#34;13.043478&#34;},{&#34;1&#34;:&#34;d&#34;,&#34;2&#34;:&#34;5&#34;,&#34;3&#34;:&#34;9&#34;,&#34;4&#34;:&#34;9.782609&#34;},{&#34;1&#34;:&#34;d&#34;,&#34;2&#34;:&#34;6&#34;,&#34;3&#34;:&#34;8&#34;,&#34;4&#34;:&#34;8.695652&#34;},{&#34;1&#34;:&#34;d&#34;,&#34;2&#34;:&#34;7&#34;,&#34;3&#34;:&#34;5&#34;,&#34;4&#34;:&#34;5.434783&#34;},{&#34;1&#34;:&#34;d&#34;,&#34;2&#34;:&#34;8&#34;,&#34;3&#34;:&#34;8&#34;,&#34;4&#34;:&#34;8.695652&#34;},{&#34;1&#34;:&#34;d&#34;,&#34;2&#34;:&#34;9&#34;,&#34;3&#34;:&#34;7&#34;,&#34;4&#34;:&#34;7.608696&#34;},{&#34;1&#34;:&#34;d&#34;,&#34;2&#34;:&#34;10&#34;,&#34;3&#34;:&#34;9&#34;,&#34;4&#34;:&#34;9.782609&#34;},{&#34;1&#34;:&#34;e&#34;,&#34;2&#34;:&#34;1&#34;,&#34;3&#34;:&#34;9&#34;,&#34;4&#34;:&#34;8.411215&#34;},{&#34;1&#34;:&#34;e&#34;,&#34;2&#34;:&#34;2&#34;,&#34;3&#34;:&#34;17&#34;,&#34;4&#34;:&#34;15.887850&#34;},{&#34;1&#34;:&#34;e&#34;,&#34;2&#34;:&#34;3&#34;,&#34;3&#34;:&#34;6&#34;,&#34;4&#34;:&#34;5.607477&#34;},{&#34;1&#34;:&#34;e&#34;,&#34;2&#34;:&#34;4&#34;,&#34;3&#34;:&#34;12&#34;,&#34;4&#34;:&#34;11.214953&#34;},{&#34;1&#34;:&#34;e&#34;,&#34;2&#34;:&#34;5&#34;,&#34;3&#34;:&#34;8&#34;,&#34;4&#34;:&#34;7.476636&#34;},{&#34;1&#34;:&#34;e&#34;,&#34;2&#34;:&#34;6&#34;,&#34;3&#34;:&#34;6&#34;,&#34;4&#34;:&#34;5.607477&#34;},{&#34;1&#34;:&#34;e&#34;,&#34;2&#34;:&#34;7&#34;,&#34;3&#34;:&#34;10&#34;,&#34;4&#34;:&#34;9.345794&#34;},{&#34;1&#34;:&#34;e&#34;,&#34;2&#34;:&#34;8&#34;,&#34;3&#34;:&#34;9&#34;,&#34;4&#34;:&#34;8.411215&#34;},{&#34;1&#34;:&#34;e&#34;,&#34;2&#34;:&#34;9&#34;,&#34;3&#34;:&#34;15&#34;,&#34;4&#34;:&#34;14.018692&#34;},{&#34;1&#34;:&#34;e&#34;,&#34;2&#34;:&#34;10&#34;,&#34;3&#34;:&#34;15&#34;,&#34;4&#34;:&#34;14.018692&#34;}],&#34;options&#34;:{&#34;columns&#34;:{&#34;min&#34;:{},&#34;max&#34;:[10]},&#34;rows&#34;:{&#34;min&#34;:[10],&#34;max&#34;:[10]},&#34;pages&#34;:{}}}
  &lt;/script&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Why this is failing?</title>
      <link>/publication/problem-3/</link>
      <pubDate>Wed, 16 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>/publication/problem-3/</guid>
      <description>
&lt;link href=&#34;/rmarkdown-libs/pagedtable/css/pagedtable.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;script src=&#34;/rmarkdown-libs/pagedtable/js/pagedtable.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;This is a pretty typical issue. Specially when you have dealing with data a long time you just stop seeing obvious things, and you just can¬¥t find solution to inexistant problems. For instance:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mtcars %&amp;gt;%
  filter(cyl &amp;lt; 4)&lt;/code&gt;&lt;/pre&gt;
&lt;div data-pagedtable=&#34;false&#34;&gt;
&lt;script data-pagedtable-source type=&#34;application/json&#34;&gt;
{&#34;columns&#34;:[{&#34;label&#34;:[&#34;mpg&#34;],&#34;name&#34;:[1],&#34;type&#34;:[&#34;dbl&#34;],&#34;align&#34;:[&#34;right&#34;]},{&#34;label&#34;:[&#34;cyl&#34;],&#34;name&#34;:[2],&#34;type&#34;:[&#34;dbl&#34;],&#34;align&#34;:[&#34;right&#34;]},{&#34;label&#34;:[&#34;disp&#34;],&#34;name&#34;:[3],&#34;type&#34;:[&#34;dbl&#34;],&#34;align&#34;:[&#34;right&#34;]},{&#34;label&#34;:[&#34;hp&#34;],&#34;name&#34;:[4],&#34;type&#34;:[&#34;dbl&#34;],&#34;align&#34;:[&#34;right&#34;]},{&#34;label&#34;:[&#34;drat&#34;],&#34;name&#34;:[5],&#34;type&#34;:[&#34;dbl&#34;],&#34;align&#34;:[&#34;right&#34;]},{&#34;label&#34;:[&#34;wt&#34;],&#34;name&#34;:[6],&#34;type&#34;:[&#34;dbl&#34;],&#34;align&#34;:[&#34;right&#34;]},{&#34;label&#34;:[&#34;qsec&#34;],&#34;name&#34;:[7],&#34;type&#34;:[&#34;dbl&#34;],&#34;align&#34;:[&#34;right&#34;]},{&#34;label&#34;:[&#34;vs&#34;],&#34;name&#34;:[8],&#34;type&#34;:[&#34;dbl&#34;],&#34;align&#34;:[&#34;right&#34;]},{&#34;label&#34;:[&#34;am&#34;],&#34;name&#34;:[9],&#34;type&#34;:[&#34;dbl&#34;],&#34;align&#34;:[&#34;right&#34;]},{&#34;label&#34;:[&#34;gear&#34;],&#34;name&#34;:[10],&#34;type&#34;:[&#34;dbl&#34;],&#34;align&#34;:[&#34;right&#34;]},{&#34;label&#34;:[&#34;carb&#34;],&#34;name&#34;:[11],&#34;type&#34;:[&#34;dbl&#34;],&#34;align&#34;:[&#34;right&#34;]}],&#34;data&#34;:[],&#34;options&#34;:{&#34;columns&#34;:{&#34;min&#34;:{},&#34;max&#34;:[10]},&#34;rows&#34;:{&#34;min&#34;:[10],&#34;max&#34;:[10]},&#34;pages&#34;:{}}}
  &lt;/script&gt;
&lt;/div&gt;
&lt;p&gt;You want to get the rows having cyl less or equal to 4 and for quite a while you keep getting 0 results.
Obviously something is wrong with the code but you just can¬¥t notice it.&lt;/p&gt;
&lt;div id=&#34;the-solution&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The Solution&lt;/h2&gt;
&lt;p&gt;Well tidylog can give you an idea. Just load tidylog and watch:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#loading the package this way to avoid verbose messages
library(tidylog)
mtcars %&amp;gt;%
  filter(cyl &amp;lt; 4)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## filter: removed all rows (100%)&lt;/code&gt;&lt;/pre&gt;
&lt;div data-pagedtable=&#34;false&#34;&gt;
&lt;script data-pagedtable-source type=&#34;application/json&#34;&gt;
{&#34;columns&#34;:[{&#34;label&#34;:[&#34;mpg&#34;],&#34;name&#34;:[1],&#34;type&#34;:[&#34;dbl&#34;],&#34;align&#34;:[&#34;right&#34;]},{&#34;label&#34;:[&#34;cyl&#34;],&#34;name&#34;:[2],&#34;type&#34;:[&#34;dbl&#34;],&#34;align&#34;:[&#34;right&#34;]},{&#34;label&#34;:[&#34;disp&#34;],&#34;name&#34;:[3],&#34;type&#34;:[&#34;dbl&#34;],&#34;align&#34;:[&#34;right&#34;]},{&#34;label&#34;:[&#34;hp&#34;],&#34;name&#34;:[4],&#34;type&#34;:[&#34;dbl&#34;],&#34;align&#34;:[&#34;right&#34;]},{&#34;label&#34;:[&#34;drat&#34;],&#34;name&#34;:[5],&#34;type&#34;:[&#34;dbl&#34;],&#34;align&#34;:[&#34;right&#34;]},{&#34;label&#34;:[&#34;wt&#34;],&#34;name&#34;:[6],&#34;type&#34;:[&#34;dbl&#34;],&#34;align&#34;:[&#34;right&#34;]},{&#34;label&#34;:[&#34;qsec&#34;],&#34;name&#34;:[7],&#34;type&#34;:[&#34;dbl&#34;],&#34;align&#34;:[&#34;right&#34;]},{&#34;label&#34;:[&#34;vs&#34;],&#34;name&#34;:[8],&#34;type&#34;:[&#34;dbl&#34;],&#34;align&#34;:[&#34;right&#34;]},{&#34;label&#34;:[&#34;am&#34;],&#34;name&#34;:[9],&#34;type&#34;:[&#34;dbl&#34;],&#34;align&#34;:[&#34;right&#34;]},{&#34;label&#34;:[&#34;gear&#34;],&#34;name&#34;:[10],&#34;type&#34;:[&#34;dbl&#34;],&#34;align&#34;:[&#34;right&#34;]},{&#34;label&#34;:[&#34;carb&#34;],&#34;name&#34;:[11],&#34;type&#34;:[&#34;dbl&#34;],&#34;align&#34;:[&#34;right&#34;]}],&#34;data&#34;:[],&#34;options&#34;:{&#34;columns&#34;:{&#34;min&#34;:{},&#34;max&#34;:[10]},&#34;rows&#34;:{&#34;min&#34;:[10],&#34;max&#34;:[10]},&#34;pages&#34;:{}}}
  &lt;/script&gt;
&lt;/div&gt;
&lt;p&gt;Tidylog produces short log messages for dplyr and tidyr operations that help you understand what is happening with the data. Here definitely filter is incorrect, not producing an error but removing the 100% of the data, that is not what I was looking for.&lt;/p&gt;
&lt;p&gt;Everytime you build a pipeline, tidylog will tell what is happening:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mtcars %&amp;gt;%
  filter(cyl &amp;gt; 4) %&amp;gt;%
  select(-disp) %&amp;gt;%
  mutate( overall = rowMeans(.)) %&amp;gt;%
  summarize_all( ~ mean(.))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## filter: removed 11 rows (34%), 21 rows remaining&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## select: dropped one variable (disp)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## mutate: new variable &amp;#39;overall&amp;#39; with 21 unique values and 0% NA&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## summarize_all: now one row and 11 columns, ungrouped&lt;/code&gt;&lt;/pre&gt;
&lt;div data-pagedtable=&#34;false&#34;&gt;
&lt;script data-pagedtable-source type=&#34;application/json&#34;&gt;
{&#34;columns&#34;:[{&#34;label&#34;:[&#34;mpg&#34;],&#34;name&#34;:[1],&#34;type&#34;:[&#34;dbl&#34;],&#34;align&#34;:[&#34;right&#34;]},{&#34;label&#34;:[&#34;cyl&#34;],&#34;name&#34;:[2],&#34;type&#34;:[&#34;dbl&#34;],&#34;align&#34;:[&#34;right&#34;]},{&#34;label&#34;:[&#34;hp&#34;],&#34;name&#34;:[3],&#34;type&#34;:[&#34;dbl&#34;],&#34;align&#34;:[&#34;right&#34;]},{&#34;label&#34;:[&#34;drat&#34;],&#34;name&#34;:[4],&#34;type&#34;:[&#34;dbl&#34;],&#34;align&#34;:[&#34;right&#34;]},{&#34;label&#34;:[&#34;wt&#34;],&#34;name&#34;:[5],&#34;type&#34;:[&#34;dbl&#34;],&#34;align&#34;:[&#34;right&#34;]},{&#34;label&#34;:[&#34;qsec&#34;],&#34;name&#34;:[6],&#34;type&#34;:[&#34;dbl&#34;],&#34;align&#34;:[&#34;right&#34;]},{&#34;label&#34;:[&#34;vs&#34;],&#34;name&#34;:[7],&#34;type&#34;:[&#34;dbl&#34;],&#34;align&#34;:[&#34;right&#34;]},{&#34;label&#34;:[&#34;am&#34;],&#34;name&#34;:[8],&#34;type&#34;:[&#34;dbl&#34;],&#34;align&#34;:[&#34;right&#34;]},{&#34;label&#34;:[&#34;gear&#34;],&#34;name&#34;:[9],&#34;type&#34;:[&#34;dbl&#34;],&#34;align&#34;:[&#34;right&#34;]},{&#34;label&#34;:[&#34;carb&#34;],&#34;name&#34;:[10],&#34;type&#34;:[&#34;dbl&#34;],&#34;align&#34;:[&#34;right&#34;]},{&#34;label&#34;:[&#34;overall&#34;],&#34;name&#34;:[11],&#34;type&#34;:[&#34;dbl&#34;],&#34;align&#34;:[&#34;right&#34;]}],&#34;data&#34;:[{&#34;1&#34;:&#34;16.64762&#34;,&#34;2&#34;:&#34;7.333333&#34;,&#34;3&#34;:&#34;180.2381&#34;,&#34;4&#34;:&#34;3.348095&#34;,&#34;5&#34;:&#34;3.70519&#34;,&#34;6&#34;:&#34;17.17381&#34;,&#34;7&#34;:&#34;0.1904762&#34;,&#34;8&#34;:&#34;0.2380952&#34;,&#34;9&#34;:&#34;3.47619&#34;,&#34;10&#34;:&#34;3.47619&#34;,&#34;11&#34;:&#34;23.58271&#34;}],&#34;options&#34;:{&#34;columns&#34;:{&#34;min&#34;:{},&#34;max&#34;:[10]},&#34;rows&#34;:{&#34;min&#34;:[10],&#34;max&#34;:[10]},&#34;pages&#34;:{}}}
  &lt;/script&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Latin R (Days 2 and 3)</title>
      <link>/post/latin-r-ii/</link>
      <pubDate>Mon, 30 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/latin-r-ii/</guid>
      <description>


&lt;div id=&#34;latin-r-conferences-days&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Latin R (Conferences Days)&lt;/h2&gt;
&lt;p&gt;Today the Conference Days just got started, and I have to say I watched some really impresive presentations and Data Products.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Day 1&lt;/strong&gt; started with a &lt;a href=&#34;https://www.uai.cl/&#34;&gt;UAI&lt;/a&gt; local presenter talking about Sports Analytics in R, then a huge presentation by Mine Cetinkaya about Teaching R to move to specific small presentation in parallel so I was able just to watch half of the Presentations.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Day 2&lt;/strong&gt; started with a &lt;a href=&#34;https://www.uc.cl/&#34;&gt;UC&lt;/a&gt; local presenter talking about applying Data Science in R to Government Data, then Erin Ledell talked about H2o to move forward to the small presentations in Parallel. The day finished with Poster presentations and Hadley Wickham talking about different dplyr backends.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;latinr-summary&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;LatinR Summary&lt;/h1&gt;
&lt;div id=&#34;sports-analytics&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Sports Analytics&lt;/h2&gt;
&lt;center&gt;
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;es&#34; dir=&#34;ltr&#34;&gt;&lt;a href=&#34;https://twitter.com/hashtag/LatinR2019?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#LatinR2019&lt;/a&gt; partiendo con datos espaciales. Hermoso :) &lt;a href=&#34;https://t.co/xUCYltzJNi&#34;&gt;pic.twitter.com/xUCYltzJNi&lt;/a&gt;&lt;/p&gt;&amp;mdash; Steph Orellana Bello (@sporella) &lt;a href=&#34;https://twitter.com/sporella/status/1177197501247627265?ref_src=twsrc%5Etfw&#34;&gt;September 26, 2019&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;

&lt;/center&gt;
&lt;center&gt;
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;es&#34; dir=&#34;ltr&#34;&gt;Ahora &lt;a href=&#34;https://twitter.com/raimun2?ref_src=twsrc%5Etfw&#34;&gt;@raimun2&lt;/a&gt; nos cuenta c√≥mo gener√≥ sus mapas para anal√≠tica de deportes de monta√±a üó∫&lt;br&gt;&lt;br&gt;‚ùáÔ∏è 25% de la poblaci√≥n tiene un cerro a menos de 3  km de distancia&lt;br&gt;&lt;br&gt;‚ùáÔ∏è 100% un cerro a menos de 10 km de distancia &lt;a href=&#34;https://t.co/l8ziSS7yXX&#34;&gt;pic.twitter.com/l8ziSS7yXX&lt;/a&gt;&lt;/p&gt;&amp;mdash; LatinR (@LatinR_Conf) &lt;a href=&#34;https://twitter.com/LatinR_Conf/status/1177199273064173568?ref_src=twsrc%5Etfw&#34;&gt;September 26, 2019&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;

&lt;/center&gt;
&lt;p&gt;The Conference kicked off with Spatial Data applied to some kind of Mountain Trekking. The presenter showed how to use R to calculate the distances from every Santiago door to have access to the Mountains.&lt;/p&gt;
&lt;p&gt;The most interesting thing about this is that this showed the huge power of R in the Spatial Data side, that is defnitely something I have no idea.&lt;/p&gt;
&lt;p&gt;During the Presentation the following packages were presented:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;ggmap:&lt;/strong&gt; of Course from the ggplot family this package allows to work with Stamen maps that I think is some kind of Raster (Map Images).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;ElevatR:&lt;/strong&gt; to get access to Topographic Maps with Elevations for free.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Rstrava:&lt;/strong&gt; An API to get access to trekking routes.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I think this was some kind of Introduction to really interesting Spatial Presentations that showed me that there is a lot to learn about that.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;teaching-r&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Teaching R&lt;/h2&gt;
&lt;p&gt;One of my passions is Teaching R, that is why this talk was specially touching to me. I worked hard during my time in EVS to have the Best R classes possible and we made it, a lot of people learned R but there was still a lot of things I know I did wrong and a lot of Tips that Mine presented that I have never thougth about.&lt;/p&gt;
&lt;center&gt;
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;es&#34; dir=&#34;ltr&#34;&gt;.&lt;a href=&#34;https://twitter.com/minebocek?ref_src=twsrc%5Etfw&#34;&gt;@minebocek&lt;/a&gt; hablando sobre la ense√±anza de R. Las diapositivas disponibles en este enlace &lt;a href=&#34;https://t.co/GEtWKB5vjV&#34;&gt;https://t.co/GEtWKB5vjV&lt;/a&gt; &lt;a href=&#34;https://t.co/aLvWQJruVv&#34;&gt;pic.twitter.com/aLvWQJruVv&lt;/a&gt;&lt;/p&gt;&amp;mdash; LatinR (@LatinR_Conf) &lt;a href=&#34;https://twitter.com/LatinR_Conf/status/1177201090363822080?ref_src=twsrc%5Etfw&#34;&gt;September 26, 2019&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;

&lt;/center&gt;
&lt;p&gt;The whole talk can be found &lt;a href=&#34;https://speakerdeck.com/minecr/r4all-welcoming-plus-inclusive-practices-for-teaching-r&#34;&gt;here&lt;/a&gt; but there was a couple of things that I think it is important to highlight:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Using Students feedback earlier:&lt;/strong&gt; She explained is really helpful to give our students the chance to raise questions and how the material can be improved as soon as possible, speially little things like font size, voice volume, backgorund color, contents and course expectations.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Help them get help:&lt;/strong&gt; I think the best things here were {searcher}, a pakage to make automatic searchs in google or stackoverflow about errors, the well-known {reprex} and this super helpful explanation about R help format:&lt;/li&gt;
&lt;/ul&gt;
&lt;center&gt;
&lt;img src=&#34;/img/help.png&#34; /&gt;&lt;!-- --&gt;
&lt;/center&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;{livecode}&lt;/strong&gt;: Mine remarked the importance of live coding to explain workflows and give confidence to students, plus it helps to express the correct way to refer to R elements. the {livecode} package is being developed and this could be a life-changer tool for people who likes to teach.&lt;/li&gt;
&lt;li&gt;Peer review: The R community is really open and we need to encourage the constructive feedback to make each other a better useR.________&lt;/li&gt;
&lt;li&gt;Encourage creativity: I just loved this point speially in the kind of challenges that can be given, for instance, creating a Christmas tree with R.&lt;/li&gt;
&lt;/ul&gt;
&lt;center&gt;
&lt;img src=&#34;/img/christmas-tree.png&#34; /&gt;&lt;!-- --&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;div id=&#34;alicer-package&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;alicer package&lt;/h2&gt;
&lt;p&gt;For me this was the most mature and powerful data Product presented during the Conference.&lt;/p&gt;
&lt;center&gt;
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;es&#34; dir=&#34;ltr&#34;&gt;.&lt;a href=&#34;https://twitter.com/minebocek?ref_src=twsrc%5Etfw&#34;&gt;@minebocek&lt;/a&gt; hablando sobre la ense√±anza de R. Las diapositivas disponibles en este enlace &lt;a href=&#34;https://t.co/GEtWKB5vjV&#34;&gt;https://t.co/GEtWKB5vjV&lt;/a&gt; &lt;a href=&#34;https://t.co/aLvWQJruVv&#34;&gt;pic.twitter.com/aLvWQJruVv&lt;/a&gt;&lt;/p&gt;&amp;mdash; LatinR (@LatinR_Conf) &lt;a href=&#34;https://twitter.com/LatinR_Conf/status/1177201090363822080?ref_src=twsrc%5Etfw&#34;&gt;September 26, 2019&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;

&lt;/center&gt;
&lt;p&gt;My main takeaways from this presentation are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;You don¬¥t need to be Hadley to create an awesome package.&lt;/li&gt;
&lt;li&gt;Use {usethis}.&lt;/li&gt;
&lt;li&gt;Give clear instructions to users.&lt;/li&gt;
&lt;li&gt;If you have Functions used 3 times, it¬¥s time to create a Package.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;hadleys-talk&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Hadley¬¥s Talk&lt;/h2&gt;
&lt;p&gt;This is always I had waited for a long time. I used to follow the different talks he is giving around the world, because he is always presenting interesting things and that day he presented dplyr backends. Of course dbplyr is super interesting and I don¬¥t want to overlook it, but I already knew it, and use it oftenly, so not very impressed. But {dtplyr} I think is something I had been waiting for a while.&lt;/p&gt;
&lt;p&gt;During the start of the year I was stalking Hadley¬¥s Repos and I just found this abandoned dtplyr, and he decided to revisit during this year and they just came up with something awesome. I don¬¥t like data.table just because of the syntax, and I love dplyr just because of the syntax, so ombining effiiency that data.table has with dplyr simplicity is just the best thing ever, and a great way to show the collaborative spirit that exist in the R Community.&lt;/p&gt;
&lt;p&gt;Just a fun fact, I asked about some new possible backends for arrays, and Hadley presented the {rray} package (check it out). For some reason he wanted to show the package logo, and he couldn¬¥t so he opened a PR just to show me that. The fun thing is that David Vaughan the maintainer, quickly responded to that.&lt;/p&gt;
&lt;center&gt;
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;I feel honored that &lt;a href=&#34;https://twitter.com/hadleywickham?ref_src=twsrc%5Etfw&#34;&gt;@hadleywickham&lt;/a&gt; raised a PR just to show me this awesome {rray} logo at &lt;a href=&#34;https://twitter.com/LatinR_Conf?ref_src=twsrc%5Etfw&#34;&gt;@LatinR_Conf&lt;/a&gt;. And the best thing was that it was responded pretty quick. XD&lt;a href=&#34;https://twitter.com/hashtag/LatinR2019?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#LatinR2019&lt;/a&gt; &lt;a href=&#34;https://t.co/i5hbIe5Cns&#34;&gt;https://t.co/i5hbIe5Cns&lt;/a&gt;&lt;/p&gt;&amp;mdash; Alfonso Tobar (@tobar_with_R) &lt;a href=&#34;https://twitter.com/tobar_with_R/status/1178021572860420097?ref_src=twsrc%5Etfw&#34;&gt;September 28, 2019&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;

&lt;/center&gt;
&lt;p&gt;Main takeaways:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Hadley is a great teacher and presenter.&lt;/li&gt;
&lt;li&gt;I can¬¥t believe how creative Hadley is and I know a lot of interesting things I just can¬¥t imagine will start to come up in R.&lt;/li&gt;
&lt;li&gt;I just learned sparklyr is a dplyr implementation in spark (sorry it was not presented).&lt;/li&gt;
&lt;li&gt;I want to work in RStudio, some time.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Latin R (Day 1)</title>
      <link>/post/latin-r-i/</link>
      <pubDate>Wed, 25 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/latin-r-i/</guid>
      <description>


&lt;div id=&#34;latin-r-tutorials-day&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Latin R (Tutorials Day)&lt;/h2&gt;
&lt;p&gt;Today Latin R just got started. It was really impressive to see how many people actually uses R. I have to say the popularity of Python in Data Science has always been something that worries me tons, but today I was able to see a lot of other Areas where people actually use R. Probably I was one of the few people working in Data Science there.&lt;/p&gt;
&lt;p&gt;Regarding Tutorials, they were awesome. 4 Tutorials were conducted today.&lt;/p&gt;
&lt;p&gt;During Morning, Mine √áetinkaya-Rundel taught about Teaching R. I wasn¬¥t there so I cannot comment a lot. In parallel Erin Ledell taught about using H2o for Machine Learning.&lt;/p&gt;
&lt;p&gt;In the afternoon, Joshua Kunst taught about Highcharter with plotly for data Viz and of course Hadley Wickham was in charge of teaching about Package Development.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;h2o-tutorial&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;H2o Tutorial&lt;/h1&gt;
&lt;center&gt;
&lt;img src=&#34;/img/h20-ai.png&#34; /&gt;&lt;!-- --&gt;
&lt;/center&gt;
&lt;p&gt;&lt;a href=&#34;https://twitter.com/ledell&#34;&gt;Erin Ledell&lt;/a&gt; conducted this tutorial that was more like a demonstration of the capabilities of H2o. I have to say I had heard about H2o in Matt Danchos‚Äô tutorials but I never got impressed because I¬¥m a super fan of Tidymodels and H2o is not there yet.&lt;/p&gt;
&lt;p&gt;For me I think a great tool was presented. H2o is a Java implementation of several Machine Learning Models. This includes Pre-processing, Grid Search, Cross Validation, Stacked Models and running in Clusters using CPU and GPU, The best is that it¬¥s absolutely free.&lt;/p&gt;
&lt;div id=&#34;pros&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Pros&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Super easy and Intuitive syntax. Very similar to parsnip.&lt;/li&gt;
&lt;li&gt;Super fast implementation in Java.&lt;/li&gt;
&lt;li&gt;It has a variety of Models including GLM, Random Forest, SVM, even some Deep Learning things.&lt;/li&gt;
&lt;li&gt;It has a localhost implementation with a GUI interface for non-coders.&lt;/li&gt;
&lt;li&gt;Runs super smoothly in Rstudio.cloud.&lt;/li&gt;
&lt;li&gt;Offers Stacked Models and AutoML algorithms.&lt;/li&gt;
&lt;li&gt;Super Easy Implementation into Production.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;downsides&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Downsides&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;It needs Java 8-12 to be installed. And Installing it is a pain.&lt;/li&gt;
&lt;li&gt;xgboost is not implemented for Windows users (this is a huge setback).&lt;/li&gt;
&lt;li&gt;Classification or Regression Problems are detected depending on the data type of the Target Variable. (Not a huge issue but I like to have control over that).&lt;/li&gt;
&lt;li&gt;It tends to oversimplify things running things behind the scenes to facilitate user experience, but you don¬¥t always are aware of things happening.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;overall&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Overall&lt;/h3&gt;
&lt;p&gt;Don¬¥t get me wrong. H2o is awesome and a great starting point for people recently learning about Machine Learning and for experienced Machine Learning people that want speed and scalability.&lt;/p&gt;
&lt;p&gt;It also offers AutoML and stacked ensembles that with little work can help to achieve excellent performance.&lt;/p&gt;
&lt;p&gt;Another think I liked, more like a side note, was that running this into Rstudio cloud was super smooth. I just had to install the h2o package as any other R package and that was it. The internet was not the best and even so everything ran super fast.&lt;/p&gt;
&lt;p&gt;Finally Erin mentioned that &lt;a href=&#34;https://twitter.com/topepos&#34;&gt;Max Kuhn&lt;/a&gt; and his team is working on integrating H2o with the TidyModels ecosystem. If that happens H2o will start being definitely one of my favorites even more.&lt;/p&gt;
&lt;p&gt;I think I will share a short tutorial about the commands I learned during the tutorial.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;package-development-tutorial&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Package Development Tutorial&lt;/h1&gt;
&lt;center&gt;
&lt;img src=&#34;/img/pkg_dev.png&#34; /&gt;&lt;!-- --&gt;
&lt;/center&gt;
&lt;p&gt;&lt;a href=&#34;http://hadley.nz/&#34;&gt;Hadley Wickham&lt;/a&gt; was in charge of this Tutorial and it was huge.&lt;/p&gt;
&lt;p&gt;The content was not a big deal, he showed the necessary steps to create a package that is actually easier than expected. But the way he directed the class:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;4 to 5 TAs to help people in need by using a Post-it signal to ask for help without interrupting the class.&lt;/li&gt;
&lt;li&gt;A lot of hands-on exercises.&lt;/li&gt;
&lt;li&gt;Makes us meet our neighbors to work peer to peer.&lt;/li&gt;
&lt;li&gt;And the usethis package.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The &lt;a href=&#34;https://usethis.r-lib.org/&#34;&gt;usethis&lt;/a&gt; Package was a huge deal. I had heard about it but I never dimensioned how powerful it is.&lt;/p&gt;
&lt;p&gt;First it helps simplify really tedious process in the Package development such as the Creation of Package Directories, edit &lt;em&gt;.Rprofile&lt;/em&gt; file, even share Material or Courses. It also creates test files to run with testthat (another super great package), helps create vignettes, upload to github, set Travis and create pkgdown sites.&lt;/p&gt;
&lt;p&gt;I think usethis is one of the great great things I take away during this Tutorial. Another great surprise is the utility of roxygen2. I know that is &lt;strong&gt;THE&lt;/strong&gt; package for Documentation purposes but today I really understood how important it is. It really simplifies Documentation creation but also helps compile all the tedious Documentation files that are mandatory to pass CRAN checks.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;lessons-learned&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Lessons learned&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;To value my job. Hadley had all of its work, including PDF files licensed and I think that gives value to the things you do.&lt;/li&gt;
&lt;li&gt;If a package is on CRAN is because the creator put a lot of love in it. Because submitting is so convoluted and tedious that if you work that hard to pass CRAN checks is because you really think you are contributing with something that is important to you as creator. Hadley mentioned that submitting to CRAN gives credibility to the author, quality to the actual package because of all of the test that needs to pass to be accepted and a lot of experience as an R Programmer.&lt;/li&gt;
&lt;li&gt;I don¬¥t feel fully prepared to create a huge package yet, but I¬¥m not afraid anymore.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;My goal after this: My Thesis definitely needs to end up into a package. I¬¥ll do my best.&lt;/p&gt;
&lt;p&gt;One of Hadley best tips:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;‚ÄúFinish your daily work with a test failing so you can now exactly how to resume your work the next day.‚Äù&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Tomorrow is day 2. Stay tuned!!&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Latin R</title>
      <link>/post/latin-r/</link>
      <pubDate>Tue, 24 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/latin-r/</guid>
      <description>


&lt;div id=&#34;latin-r&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Latin R&lt;/h2&gt;
&lt;p&gt;Latin R is a conference organized by RLadies Latam and is the oportunity we have here in Chile to get acquainted about the last R breakthrough and how is being using in Research, companies, etc.
They also provide a full day of Tutorials and of course important keynotes are invited to come over. This year I think is huge, because 3 Main R users are coming:&lt;/p&gt;
&lt;div id=&#34;mine-√ßetinkaya-rundel&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Mine √áetinkaya-Rundel&lt;/h3&gt;
&lt;p&gt;She is one of the most important persons involved into R Teaching. Statistics Professor from Duke University. I personally had the chance to take some Coursera and Datacamp Courses with her and I learned a lot, really good teacher and really knowledgable. Having her now here in Chile to meet her in person is such a great Honor. I just can¬¥t wait to hear about what she has to say.
She will be conducting a Tutorial on how to Teach R and of Course a main Speech.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;erin-ledell&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Erin Ledell&lt;/h3&gt;
&lt;p&gt;I have to say I don‚Äôt know a lot about her but she has a great curriculum: Chief Machine Learning Scientist at H2O, co-founder of Rladies Global and Woman+ in ML/DS, plus BioStatistics Phd at Berkeley, that is more than enough. She will be conducting a Tutorial on Machine Learning and Deep Learning that of course I¬¥ll be taking so I¬¥ll give more details on a later post.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;hadley-wickham&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Hadley Wickham&lt;/h3&gt;
&lt;p&gt;This Guy needs no Introduction. He is the Chief Scientist at RStudio and he will be giving the Main Speech of the Conference plus a Package Development Tutorial. Of ourse I will be in first row of this Tutorial and I expect to learn a lot and have a lot of questions prepared beforehand.&lt;/p&gt;
&lt;p&gt;This guys is by far my most important inspiration when it comes to working in R. Definitely this guy has made my life way easier because of all of the packages that he has created and I use almost every day.&lt;/p&gt;
&lt;p&gt;I‚Äôll be the next 3 days in the Conference and I expect to share some pictures and experiences about the things I will learn.&lt;/p&gt;
&lt;p&gt;Stay tuned!!!&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>My Thesis</title>
      <link>/project/my-thesis/</link>
      <pubDate>Mon, 23 Sep 2019 00:00:00 -0300</pubDate>
      
      <guid>/project/my-thesis/</guid>
      <description>&lt;p&gt;Coming up with an Interesting Thesis Project is not easy at all. Actually I had 3 different projets and 5 different professors. None of them were really interested in my propositions. Thank God I found &lt;a href=&#34;http://www.ociv.usm.cl/profesores/valdebenito-c-marcos-2/&#34; target=&#34;_blank&#34;&gt;Dr. Marcos Valdebenito&lt;/a&gt;. He is really interested in Reliability Analysis in Structures and Study the Response of Random Field Variables into Strutures, you can learn more about his work on his website. Once I talked to him about I was doing in my former job he was really interested in applying Machine Learning techniques to solve this kind of problems.&lt;/p&gt;

&lt;p&gt;Normally to study the effect of Ramdom fields in Structures a Montecarlo Simulation is run several times to determine how the Structure response is affected. This is done by analyzing the mean and the Covariance of the simulations. This process is omputationally expensive since normally 10,000 to 1,000,000 simulations are needed. Every one of those simulations solves the following problem, also called the Rayleigh - Ritz Method:&lt;/p&gt;

&lt;p&gt;$$ [K] {u} = {f}$$&lt;/p&gt;

&lt;p&gt;Where $ [K] $ is the Finite Element Matrix representing the Equivalent Stiffness of the different Degrees of Fredom of the Structure.  $ {f} $ is the Equivalent Load Vector representing the forces affecting the Structure. In order to solve this problem $ [K]^{-1} $ needs to be pre-multiplied with $ {f}$ to obtain the Struture Response $ {u} $ representing the Structure displacement at every Degree of freedom. Normally $ [K] $ is a fairly large Matrix and the Inversion process costly so alternative methods to Montecarlo Simulation are deeply appreciated.&lt;/p&gt;

&lt;p&gt;So that is how we came up with a Project. What about considering $ [K] $ as a black and white image (1 channel), representing the stiffness of a Truss. Therefore, Convolutional Networks could be a good alternative to analyze the Matrix and train a Network capable of determinimg in a first instance the displacement of the Structure (${u}$) and afterwards the failure of the Structure, transforming the problem into a Clasification Binary Problem (Failing - not Failing).&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;ll be posting more technical content about how I&amp;rsquo;ve been tackling the problem. Stay tuned!!!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The Stiffness Method</title>
      <link>/project/stiffness-method/</link>
      <pubDate>Mon, 23 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>/project/stiffness-method/</guid>
      <description>

&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#the-method&#34;&gt;The Method&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#the-problem&#34;&gt;The Problem&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#rcpp-basics&#34;&gt;Rcpp Basics&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#creating-an-rcpp-file&#34;&gt;Creating an Rcpp file&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#stiffness-method&#34;&gt;Stiffness Method&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#stiff-matrix-by-element&#34;&gt;Stiff Matrix by Element&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#active-dof-assembly&#34;&gt;Active DoF Assembly&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#connectivity-array&#34;&gt;Connectivity Array&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#stiffness-matrix-assembly&#34;&gt;Stiffness Matrix Assembly&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#load-vector-assembly&#34;&gt;Load Vector Assembly&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#solving-the-problem&#34;&gt;Solving the Problem&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#conclusions&#34;&gt;Conclusions&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;div id=&#34;the-method&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;The Method&lt;/h1&gt;
&lt;p&gt;The Rayleigh Ritz Method is nothing but applying Finite Elements to Structural problems. Basically you split your structure into smaller structures that can easily be solved By solving, I mean, Calculate the specific stifness of the Structure in order to determine how the loads affects the structure. Once the individual mini-strutures are solved they are ensembled into a Merged Matrix equivalent to the total Stiffness of the Structure.&lt;/p&gt;
&lt;p&gt;The purpose of this Document is not get into deep details about the Method. If you want to learn about this you can go to this &lt;a href=&#34;https://www.sciencedirect.com/topics/engineering/stiffness-method&#34;&gt;paper&lt;/a&gt; to learn the Maths behind this. The idea is to show how to implement this in R. Since this is a computational expensive method I‚Äôll be using &lt;code&gt;library(Rcpp)&lt;/code&gt;.&lt;/p&gt;
&lt;div id=&#34;the-problem&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The Problem&lt;/h2&gt;
&lt;center&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:figs1&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;/img/3_bar_problem.jpg&#34; alt=&#34;\label{fig:figs1}Problem Structure&#34;  /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 1: Problem Structure
&lt;/p&gt;
&lt;/div&gt;
&lt;/center&gt;
&lt;p&gt;This is a simple problem and useful to understand the different steps of the Method.
This is implementation is for a Truss with 3 Nodes and 3 Elements where:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Number of Nodes by Element
NN_e &amp;lt;- 2
#Number of Degrees of Freedom (DoF) by Node
Ngl_N &amp;lt;- 2
L &amp;lt;- 1 #Value of L
E &amp;lt;- 2 * 10 ^ 11 # Young Module / Elasticity Metric
A &amp;lt;- 0.0001 # Cross Sectional Area
P &amp;lt;- 1000 # Load&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The First and most simple Step is to organize the Input Data. All of the Data will be input in &lt;code&gt;tibble&lt;/code&gt; form.&lt;/p&gt;
&lt;p&gt;Row i of the &lt;code&gt;Nodes&lt;/code&gt; Matrix will store the X and Y Coordinates for Every Node.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;(Nodes &amp;lt;-
   tibble::tribble(~ Xi, ~ Yi,
                   0,   0,
                   sqrt(2) / 2 * L,  sqrt(2) / 2 * L,
                   sqrt(2) * L, 0))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 3 x 2
##      Xi    Yi
##   &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1 0     0    
## 2 0.707 0.707
## 3 1.41  0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The Row j of the &lt;code&gt;Elements&lt;/code&gt; Matrix will contain the Initial Node &lt;code&gt;ni&lt;/code&gt;, the ending Node &lt;code&gt;nf&lt;/code&gt; and the corresponding E and A properties for Element j. In this case all the Elements share the same properties.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;(Elements &amp;lt;-
   tibble::tribble(~ ni, ~ nf,   ~ E,   ~ A,
                   1,   2,    E,    A,
                   2,   3,    E,    A,
                   3,   1,    E,    A))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 3 x 4
##      ni    nf            E      A
##   &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;        &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;
## 1     1     2 200000000000 0.0001
## 2     2     3 200000000000 0.0001
## 3     3     1 200000000000 0.0001&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The Row i of the &lt;code&gt;Loads&lt;/code&gt; Matrix contains the x and y vectorial component of the Loads for Node i.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;(Loads &amp;lt;-
   tibble::tribble(~ Px, ~ Py,
                   0,   0,
                   0,   P,
                   0,   0))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 3 x 2
##      Px    Py
##   &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1     0     0
## 2     0  1000
## 3     0     0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The Row i correspond to the freedom of the X and Y Component of the Node i. 1 meaning no Movement and 0 meaning free movement.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;(Supports &amp;lt;-
   tibble::tribble(~ Rx, ~ Ry,
                   1,   1,
                   0,   0,
                   0,   1))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 3 x 2
##      Rx    Ry
##   &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1     1     1
## 2     0     0
## 3     0     1&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;rcpp-basics&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Rcpp Basics&lt;/h2&gt;
&lt;p&gt;Rcpp is the R API package to access to the huge benefits that C++ offers. I¬¥m not an expert in C++ actually I just learned a bit of C++ because Rcpp offers easy sintax to access to C++ Elements but always showing equivalents in the R Environment.&lt;/p&gt;
&lt;p&gt;C++ is far for being an adequate language for Data Science, but once you want to optimize code or algorithms is definitely the way to go. In these case I¬¥ll be showing the algorithm to the different steps of the Stiffness Method and how can be implemented in Rcpp.&lt;/p&gt;
&lt;p&gt;My main sources to learn Rcpp were this excellent &lt;a href=&#34;https://teuder.github.io/rcpp4everyone_en/&#34;&gt;Rcpp for Everyone&lt;/a&gt; and of course &lt;a href=&#34;http://adv-r.had.co.nz/Rcpp.html&#34;&gt;Hadley¬¥s Help&lt;/a&gt;. With these two resources you should have more than enough to create your first Rcpp functions.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;creating-an-rcpp-file&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Creating an Rcpp file&lt;/h2&gt;
&lt;center&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:figs2&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;/img/cpp_file.png&#34; alt=&#34;\label{fig:figs2}Create a C++ File&#34;  /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 2: Create a C++ File
&lt;/p&gt;
&lt;/div&gt;
&lt;/center&gt;
&lt;p&gt;If you work with RStudio you can go to File &amp;gt; New File &amp;gt; C++ File and will open a C++ Template like this:&lt;/p&gt;
&lt;center&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:figs3&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;/img/cpp_template.png&#34; alt=&#34;\label{fig:figs3}C++ Template&#34;  /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 3: C++ Template
&lt;/p&gt;
&lt;/div&gt;
&lt;/center&gt;
&lt;p&gt;The main thing you need to be aware of is loading the required libraries from C++. In this case we will use the following:&lt;/p&gt;
&lt;p&gt;All C++ code chunks will be combined to the chunk below:&lt;/p&gt;
&lt;pre class=&#34;cpp&#34;&gt;&lt;code&gt;// [[Rcpp::depends(RcppEigen)]]
#include &amp;lt;Rcpp.h&amp;gt;
#include &amp;lt;RcppEigen.h&amp;gt;
#include &amp;lt;Eigen/LU&amp;gt; 
#include &amp;lt;Eigen/Eigenvalues&amp;gt; 

using namespace Rcpp;
using namespace Eigen;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As you may know C++ is a compiled language. Compilation means, in really simple words, to optimize and speed up the code making it available in R through functions. If you want functions to be available in the R environment they need to be preceeded by this special comment. Otherwise they can be called from within the C++ environment as intermediate functions but they won¬¥t work in R.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;stiffness-method&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Stiffness Method&lt;/h2&gt;
&lt;div id=&#34;stiff-matrix-by-element&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Stiff Matrix by Element&lt;/h3&gt;
&lt;p&gt;This Step calculates Stiff for the mini-structures, meaning every single bar.&lt;/p&gt;
&lt;p&gt;Every Element Matrix has the following form that needs to be created according to its properties.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
[K]_j=\begin{bmatrix}
    c^2 &amp;amp;  &amp;amp;  &amp;amp; sim\\
    cs &amp;amp; s^2 &amp;amp;  &amp;amp; \\
    -c^2 &amp;amp; -cs &amp;amp; c^2 &amp;amp; \\
    -cs &amp;amp; -s^2 &amp;amp; cs &amp;amp; s^2 \\
    \end{bmatrix}
\]&lt;/span&gt;
The pseudo code is as follows:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ Ne \leftarrow \text{Number of Rows in the Element Matrix} \\
c \leftarrow  \text{ Sparse Matrix for Director Cosines, Dimension Ne x 1 } \\
s \leftarrow  \text{ Sparse Matrix for Director Sinus, Dimension Ne x 1 } \\
L \leftarrow  \text{ Sparse Matrix for Element Length, Dimension Ne x 1 } \\
\text{for j = 1 to Ne do}
\left\{ \begin{array}{lcc}
             Ni=Elements(j,1) \\ 
             Nf=Elements(j,2) \\
             \Delta x = Nodes(Nf,1) - Nodes(Ni,1) \\
             \Delta y = Nodes(Nf,2) - Nodes(Ni,2) \\
             L(j)=\sqrt{\Delta x^2 + \Delta y^2} \\
             c(j) = {\Delta x\over L(j)} \\
             s(j) = {\Delta y\over L(j)}
             \end{array}
   \right.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Now translating this into Rcpp looks like this:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;You need define every object to use preceeded by its type.&lt;/li&gt;
&lt;li&gt;The output will be an R List since I want object storing the different Element Matrix.&lt;/li&gt;
&lt;li&gt;All of the Function arguments are Mandatory by default and need to go in the same order that will be used. If an Optional Argument is needed the default value needs to be defined as in NN_e.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;cpp&#34;&gt;&lt;code&gt;// [[Rcpp::export]]
// First you define the Output Type. In this case an R List.
List K_Element(NumericMatrix Nodes, NumericMatrix Elements, int NN_e = 2){
  
  // Ne is defined by using the nrow method to calculate number of rows.
  int Num_Elements = Elements.nrow();
  // c, s and L are defined Vectors since the second Dimension is 1.
  NumericVector c (Num_Elements);
  NumericVector s (Num_Elements);
  NumericVector L (Num_Elements);
  
  int j,Ni,Nf;
  // dx and dy are defined as doubles since they can contain decimals
  double dx,dy;
  List K_list (Num_Elements);
  
  
  // C++ is defined from 0 as the first element. So the pseudo code needs to be adjusted accordingly.
  // Notice the for syntax, from 0 to NE-1 defined as j&amp;lt;Num_Elementos and the ++j iterator
  for(j=0;j&amp;lt;Num_Elements;++j){
    Ni=Elements(j,0) -1;
    Nf=Elements(j,1) - 1;
    dx=Nodes(Nf,0)-Nodes(Ni,0);
    dy=Nodes(Nf,1)-Nodes(Ni,1);
    //pow is the C++ operator for ^
    L[j]=sqrt(pow(dx,2)+pow(dy,2));
    c(j)=dx/L(j);
    s(j)=dy/L(j);
    
  // This is a special way to define a Matrix by Element coming from library(RcppEigen)
    Matrix4f ke;
    ke &amp;lt;&amp;lt; pow(c[j],2),c[j]*s[j],-pow(c[j],2),-c[j]*s[j],
         c[j]*s[j],pow(s[j],2),-c[j]*s[j], -pow(s[j],2),
         -pow(c[j],2),-c[j]*s[j],pow(c[j],2),c[j]*s[j],
          -c[j]*s[j],-pow(s[j],2),c[j]*s[j],pow(s[j],2);
    //Here you populate every List Element with the corresponding Element Matrix
    K_list[j]= Elements(j,NN_e)*Elements(j,NN_e + 1)/L[j]*ke;  
    
    
  }
  
 
  
  return K_list;
}
/*** R
(K_E &amp;lt;- K_Element(Nodes,Elements))
*/&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;active-dof-assembly&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Active DoF Assembly&lt;/h3&gt;
&lt;p&gt;The Stiffness Method needs to determine what Dof are actually active, meaning that are free to move, hence are unknowns of the equation of the problem.
In order to do that it is necessary to determine which ones are free to move depending on the support Matrix and a Position Number is assigned to them.&lt;/p&gt;
&lt;p&gt;Pseudocode as follows:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ Nn \leftarrow \text{Number of Rows in the Node Matrix} \\
Gl_act \leftarrow  \text{ Sparse Matrix Dimension (NN \cdot Ngl_N) x 1 } \\
cont = 0 \\
\begin{aligned}
&amp;amp; \text{for i = 1 to Nn do } \\
&amp;amp; \text{for k = 1 to Ngl_N do} \\
\end{aligned} \\
\left\{ \begin{array}{lcc}
             \text{if Apoyos(i,k) = 0 then} \\
             cont= cont +1 \\
             pos=Ngl_N \cdot (i-1) + k \\
             Gl_act(pos)=cont \\
             \end{array}
   \right.
\]&lt;/span&gt;
Rcpp Code:&lt;/p&gt;
&lt;pre class=&#34;cpp&#34;&gt;&lt;code&gt;// [[Rcpp::export]] 
// Sparse Vector that uses Support Matrix as Input 
NumericVector Gr_Active(NumericMatrix Support, int Ngl_N = 2){
  int Num_Nodes = Support.nrow();
  int cont=0, i, k;
  //Defining Dimension of Gl Vector
  NumericVector Gl (Num_Nodes*Ngl_N);
  
  for(i = 0; i &amp;lt; Num_Nodes; ++i){
    for(k = 0; k &amp;lt; Ngl_N; ++k){
      
      if(Apoyos(i,k)==0){
        //Counter needs to be adapted since C++ starts off at Zero
        Gl[Ngl_N*i+k] = ++cont;
        
      }
    }  
    
  }
  return Gl;
  
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;connectivity-array&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Connectivity Array&lt;/h3&gt;
&lt;p&gt;The Method determines an array to identify how the different elements are connected each other. This way it is possible to create an equivalent Matrix representing the Equivalent Stiffness of the ensembled elements.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ Ngle = Ngl_N \cdot NN_e \\
conect \leftarrow  \text{ Sparse Matrix Dimension Ne x Ngle } \\
\begin{aligned}
&amp;amp; \text{for j = 1 to Ne do } \\
&amp;amp; \text{for k = 1 to NN_e do} \\
&amp;amp; N_k=Elementos(j,k) \\
&amp;amp; pos1= (N_k - 1) \cdot Ngl_N \\
\end{aligned} \\
\text{ for l= 1 to Ngl_N do } \\
\left\{ \begin{array}{lcc}
             pos2=pos1+l \\
             pos3= (k-1) \cdot Ngl_N + l \\
             conect(j,pos3) = Gl_act(pos2) \\
             \end{array}
   \right.
\]&lt;/span&gt;
Rcpp Code:&lt;/p&gt;
&lt;pre class=&#34;cpp&#34;&gt;&lt;code&gt;// [[Rcpp::export]]
// This is a Numeric Matrix using Elements Matrix and Gl Vector as Input
NumericMatrix Arr_Connect(NumericMatrix Elements, NumericVector Gl, int NN_e = 2, int Ngl_N = 2){
  int Num_Elements = Elements.nrow();
  // Several counters an be defined simultaneously if sharing the same properties.
  int j, k, l, pos1, pos2, pos3;
  NumericMatrix conect(Num_Elements, NN_e * Ngl_N);
  
  for(j=0; j &amp;lt; Num_Elements; ++j){
    for(k=0; k &amp;lt; NN_e; ++k){
      pos1 = (Elements(j,k) - 1) * Ngl_N;
      for(l=0; l &amp;lt; Ngl_N; ++l){
        pos2 = pos1 + l;
       // pos3 had to be adjusted because C++ index starting at 0     
        pos3 = k * Ngl_N + l;
        conect(j,pos3) = Gl[pos2];
      }
    }
  }
  
  return conect;
  
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;stiffness-matrix-assembly&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Stiffness Matrix Assembly&lt;/h3&gt;
&lt;p&gt;Once the Connectivity Array and the Active DoFs are determined the Global Stiffness Matrix can be assembled. This matrix contains the Contribution of every element to an specific Node. Less Elements joined to a specific Node will end up adding less stiffness than a lot of elements being part of a Node.&lt;/p&gt;
&lt;p&gt;Pseudocode as follows:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ N_R \leftarrow \text{ sum of all of the entries of the support Matrix }  \\
NGl_total = Ngl_N \cdot Nn - N_R \\
K \leftarrow \text{ Sparse Matrix Ngl_total x Ngl_total }  \\
\begin{aligned}
&amp;amp; \text{for j = 1 to Ne do } \\
&amp;amp; \text{for k = 1 to Ngle do} \\
\end{aligned} \\
\text{ for l= 1 to Ngl_e do } \\
\left\{ \begin{array}{lcc}
             pos1=conect(j,k) \\
             pos2=conect(j,l) \\
             text{ if conect(j,k) \neq 0 and conect(j,l) \neq 0 then } \\
             K(pos1,pos2)=K_E{j}(k,l) + K(pos1,pos2) \\
             \end{array}
   \right.
\]&lt;/span&gt;
Rcpp Code:&lt;/p&gt;
&lt;pre class=&#34;cpp&#34;&gt;&lt;code&gt;// [[Rcpp::export]]
//Numeric Matrix using Support, Gl and Conect Matrix and K_E List as Inputs
NumericMatrix K_Total(List K_E, NumericMatrix Support, NumericVector Gl, NumericMatrix conect, 
                      int NN_e = 2, int Ngl_N =2 ){
  
  int Num_Elements = K_E.length();
  int Num_Nodes = Support.nrow();
  int Nr=sum(Support), j, k, l, pos1, pos2;
  NumericMatrix K( Ngl_N * Num_Nodos- Nr );
  int Ngl_E = NN_e * Ngl_N;
  
  
  for(j=0; j&amp;lt;Num_Elements; ++j){
    for(k=0; k&amp;lt;Ngl_E; ++k){
      for(l=0; l&amp;lt;Ngl_E; ++l){
        pos1 = conect(j,k);
        pos2 = conect(j,l);
        //Notice that List Elements need to be pulled using brakets
        NumericMatrix Ke = K_E[j];
        // and operator uses double ampersand and inequality syntax follow same rules than R
        if(pos1 != 0 &amp;amp;&amp;amp; pos2 !=0){
          // += is the C++ operator to sum the new value to the current one.
          K(pos1 - 1, pos2 - 1) += Ke(k,l);
        }
      }
    }
  }
  
  return K;
  
  
  
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;load-vector-assembly&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Load Vector Assembly&lt;/h3&gt;
&lt;p&gt;This is the equivalent load Vector considering only Loads for active DoFs that are participating in the solution of the problem.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ F \leftarrow \text{ Sparse Matrix dimension Ngl_total x 1 }  \\
\begin{aligned}
&amp;amp; \text{for i = 1 to Nn do } \\
\end{aligned} \\
\text{ for k= 1 to Ngl_n do } \\
\left\{ \begin{array}{lcc}
             pos1=Ngl_n \cdot (i-1) + k \\
             pos2=Gl_act(pos1) \\
             \text{ if pos2 Loads(i,k) } \\
             F(pos2)=Cargas(i,k)\\
             \end{array}
   \right.
\]&lt;/span&gt;
Rcpp Code:&lt;/p&gt;
&lt;pre class=&#34;cpp&#34;&gt;&lt;code&gt;// [[Rcpp::export]]
NumericVector f_Total(NumericMatrix Loads, NumericVector Gl, int Nr, int Ngl_N = 2 ){
  int Num_Nodos = Loads.nrow();
  int N_t = Ngl_N * Num_Nodos - Nr;
  NumericVector F (N_t);
  int i,k,pos1,pos2;
  
  for(i=0; i &amp;lt; Num_Nodos; ++i){
    for(k=0; k &amp;lt; Ngl_N; ++k){
      pos1 = Ngl_N * i + k;
      pos2 = Gl[pos1];
      if(pos2 != 0){
        F[pos2 - 1] = Cargas(i,k);
      }
    }
  }
  
  return F;
  
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;solving-the-problem&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Solving the Problem&lt;/h3&gt;
&lt;p&gt;All this Steps allows to pose the following problem:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ [K] \cdot \{u\} = \{F\} \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;In order to get the desired displacements it is just necessary to inverse $ [K] $.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[  \{u\} = [K]^{-1} \cdot \{F\}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;For this case I¬¥ll be using RcppEigen, a Rcpp Linear Algebra Library that allows some extra Matrix operations that are useful for, in this case, Matrix inversion:&lt;/p&gt;
&lt;pre class=&#34;cpp&#34;&gt;&lt;code&gt;// I have defined a new object type called MapMatd whih is a Matrix with no specific size of doubles
typedef Map&amp;lt;MatrixXd&amp;gt; MapMatd;
// Defined a Vector with same characteristics as before
typedef Map&amp;lt;VectorXd&amp;gt; MapVecd;

// [[Rcpp::export]]
// I use a VectorXd non defined size X with double data type d
VectorXd u_vect(NumericMatrix K_Total, NumericVector f_Total){
  //I need to cast R Objects coming from Inputs into Eigen Objects. In this case i would just say trust me.
  const MapMatd K(as&amp;lt;MapMatd&amp;gt;(K_Total));
  const MapVecd f(as&amp;lt;MapVecd&amp;gt;(f_Total));
  
  //Applying Inverse Method, this is only available because K and f are already Eigen objets
  VectorXd result = K.inverse()*f;
  
  return result;
  
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Conclusions&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;R and Rcpp share a very similar syntax.&lt;/li&gt;
&lt;li&gt;All R objects are compatible with Rcpp, even Lists&lt;/li&gt;
&lt;li&gt;The Main advantage of using Rcpp is that is way too faster than Regular R. This makes it especially suitable for Algorithms and Matrix manipulation.&lt;/li&gt;
&lt;li&gt;Notice that Matrices use () for indexing whereas Vectors and Lists use [].&lt;/li&gt;
&lt;li&gt;Rcpp starts at 0, make the proper adjustments when dealing with indices.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I¬¥ll be posting another Entry using the recently reated functions to show how fast they are. Stay tuned!!&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>My Final Project at the ML Diploma (Part III)</title>
      <link>/project/machine-learning-diploma-iii/</link>
      <pubDate>Tue, 27 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>/project/machine-learning-diploma-iii/</guid>
      <description>
&lt;link href=&#34;/rmarkdown-libs/pagedtable/css/pagedtable.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;script src=&#34;/rmarkdown-libs/pagedtable/js/pagedtable.js&#34;&gt;&lt;/script&gt;

&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#tidymodels&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;1&lt;/span&gt; Tidymodels&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#spliting-the-data&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;1.1&lt;/span&gt; Spliting the Data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#pre-processing&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;1.2&lt;/span&gt; Pre Processing&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#create-the-logistic-regression&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;2&lt;/span&gt; Create the Logistic Regression&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#conclusions&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;3&lt;/span&gt; Conclusions&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;p&gt;Now we have an idea on how the data looks like it is time to Model.&lt;/p&gt;
&lt;div id=&#34;tidymodels&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;&lt;span class=&#34;header-section-number&#34;&gt;1&lt;/span&gt; Tidymodels&lt;/h1&gt;
&lt;p&gt;I¬¥m a huge fan of tidymodels framework and the way Max Kuhn has put together all of this system. I¬¥ll be using several packages from this framework in order to show different steps of the Machine Learning Process.&lt;/p&gt;
&lt;div id=&#34;spliting-the-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;1.1&lt;/span&gt; Spliting the Data&lt;/h2&gt;
&lt;p&gt;We will be splitting Data into Training and Test Sets with 70/30 proportion based on the Ins Response Variable.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(rsample)
#Reproducibility
set.seed(27101986)
#70/30 Split stratifying the Target Variable Ins
split &amp;lt;- initial_split(data, prop = 0.7, strata = &amp;quot;Ins&amp;quot;)
data_training &amp;lt;- split %&amp;gt;% training()
data_testing &amp;lt;- split %&amp;gt;% testing()&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;pre-processing&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;1.2&lt;/span&gt; Pre Processing&lt;/h2&gt;
&lt;p&gt;After splitting Data I will be conducting Pre Processing with the great Recipes Package.&lt;/p&gt;
&lt;p&gt;Recipes basically mimics the Pre Processing Steps to a Baking Recipe following different sequential steps in order to prepare and Bake the Data (Make the Data Ready to Model).&lt;/p&gt;
&lt;p&gt;Recipes have &lt;code&gt;step_*&lt;/code&gt; functions in charge of applying different Pre-Processing Steps. Plus includes Variable helpers to call Variables by Type or Role.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(recipes)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Attaching package: &amp;#39;recipes&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## The following object is masked from &amp;#39;package:stringr&amp;#39;:
## 
##     fixed&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## The following object is masked from &amp;#39;package:stats&amp;#39;:
## 
##     step&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Sets the Recipe indicating that Ins will be modeled using all the rest of the variables
advance_rec &amp;lt;- recipe(Ins ~ . , data = data_training) %&amp;gt;%
  step_dummy(all_nominal(), -all_outcomes()) %&amp;gt;% #create dummy variables for all categorical variables excepting the Ins Variable
  step_nzv(all_numeric()) %&amp;gt;% #eliminates numerical variables with variance near to zero
  step_corr(all_predictors()) %&amp;gt;% #eliminates highly correlated variables
  step_BoxCox(all_predictors()) %&amp;gt;% #fix highly skewed variables
  step_center(all_numeric()) %&amp;gt;% #substracts mean
  step_scale(all_numeric()) %&amp;gt;% #divides by sd. This both steps standardize the variables
  #Prepares the data according to the data in the Training Set
  prep(training = data_training)
  
  #Applies Training Data according to Preprocessing
  train_advance &amp;lt;- bake(advance_rec, new_data = data_training)
  #The main difference with Bake is that Bake skips the processes affecting the outcome variable, suh as resamples, logs transform, etc. 
  test_advance &amp;lt;- bake(advance_rec, new_data = data_testing)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;create-the-logistic-regression&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;&lt;span class=&#34;header-section-number&#34;&gt;2&lt;/span&gt; Create the Logistic Regression&lt;/h1&gt;
&lt;p&gt;We will use Logistic regresson using Parsnip and we will Assess the Model using yardstick&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(parsnip)

#Using Parsnip to run classification, using glm engine and fitting train data already pre-processed
full_advance &amp;lt;- logistic_reg(mode = &amp;quot;classification&amp;quot;) %&amp;gt;%
                                set_engine(&amp;quot;glm&amp;quot;) %&amp;gt;%
                                  fit(Ins ~ ., data = train_advance)

#Predicting Class with Model &amp;quot;Full Advance&amp;quot; in the Test Set
full_pred_advance &amp;lt;- full_advance %&amp;gt;%
                  predict(new_data= test_advance, type = &amp;quot;class&amp;quot;)

#Predicting class Probabilities with Model &amp;quot;Full Advance&amp;quot;
full_pred_probs_advance &amp;lt;- full_advance %&amp;gt;%
                  predict(new_data= test_advance, type = &amp;quot;prob&amp;quot;)


library(yardstick)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## For binary classification, the first factor level is assumed to be the event.
## Set the global option `yardstick.event_first` to `FALSE` to change this.&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Attaching package: &amp;#39;yardstick&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## The following object is masked from &amp;#39;package:readr&amp;#39;:
## 
##     spec&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;comparison_test &amp;lt;- bind_cols(
  &amp;quot;Real&amp;quot; = test_advance$Ins,
  &amp;quot;Prediction&amp;quot; = full_pred_advance,
  &amp;quot;Class1&amp;quot; = full_pred_probs_advance$.pred_yes
  
) %&amp;gt;% setNames(c(&amp;quot;Real&amp;quot;,&amp;quot;Prediction&amp;quot;,&amp;quot;Class1&amp;quot;))

#Calculating Confusion Matrix
comparison_test %&amp;gt;% 
    conf_mat(Real,Prediction)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##           Truth
## Prediction  yes   no
##        yes 1003  464
##        no  1248 3547&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Calculating Assesment Metrics for Model
comparison_test %&amp;gt;% 
    conf_mat(Real,Prediction) %&amp;gt;%
    summary()&lt;/code&gt;&lt;/pre&gt;
&lt;div data-pagedtable=&#34;false&#34;&gt;
&lt;script data-pagedtable-source type=&#34;application/json&#34;&gt;
{&#34;columns&#34;:[{&#34;label&#34;:[&#34;.metric&#34;],&#34;name&#34;:[1],&#34;type&#34;:[&#34;chr&#34;],&#34;align&#34;:[&#34;left&#34;]},{&#34;label&#34;:[&#34;.estimator&#34;],&#34;name&#34;:[2],&#34;type&#34;:[&#34;chr&#34;],&#34;align&#34;:[&#34;left&#34;]},{&#34;label&#34;:[&#34;.estimate&#34;],&#34;name&#34;:[3],&#34;type&#34;:[&#34;dbl&#34;],&#34;align&#34;:[&#34;right&#34;]}],&#34;data&#34;:[{&#34;1&#34;:&#34;accuracy&#34;,&#34;2&#34;:&#34;binary&#34;,&#34;3&#34;:&#34;0.7266049&#34;},{&#34;1&#34;:&#34;kap&#34;,&#34;2&#34;:&#34;binary&#34;,&#34;3&#34;:&#34;0.3571922&#34;},{&#34;1&#34;:&#34;sens&#34;,&#34;2&#34;:&#34;binary&#34;,&#34;3&#34;:&#34;0.4455797&#34;},{&#34;1&#34;:&#34;spec&#34;,&#34;2&#34;:&#34;binary&#34;,&#34;3&#34;:&#34;0.8843181&#34;},{&#34;1&#34;:&#34;ppv&#34;,&#34;2&#34;:&#34;binary&#34;,&#34;3&#34;:&#34;0.6837082&#34;},{&#34;1&#34;:&#34;npv&#34;,&#34;2&#34;:&#34;binary&#34;,&#34;3&#34;:&#34;0.7397289&#34;},{&#34;1&#34;:&#34;mcc&#34;,&#34;2&#34;:&#34;binary&#34;,&#34;3&#34;:&#34;0.3737526&#34;},{&#34;1&#34;:&#34;j_index&#34;,&#34;2&#34;:&#34;binary&#34;,&#34;3&#34;:&#34;0.3298979&#34;},{&#34;1&#34;:&#34;bal_accuracy&#34;,&#34;2&#34;:&#34;binary&#34;,&#34;3&#34;:&#34;0.6649489&#34;},{&#34;1&#34;:&#34;detection_prevalence&#34;,&#34;2&#34;:&#34;binary&#34;,&#34;3&#34;:&#34;0.2342702&#34;},{&#34;1&#34;:&#34;precision&#34;,&#34;2&#34;:&#34;binary&#34;,&#34;3&#34;:&#34;0.6837082&#34;},{&#34;1&#34;:&#34;recall&#34;,&#34;2&#34;:&#34;binary&#34;,&#34;3&#34;:&#34;0.4455797&#34;},{&#34;1&#34;:&#34;f_meas&#34;,&#34;2&#34;:&#34;binary&#34;,&#34;3&#34;:&#34;0.5395374&#34;}],&#34;options&#34;:{&#34;columns&#34;:{&#34;min&#34;:{},&#34;max&#34;:[10]},&#34;rows&#34;:{&#34;min&#34;:[10],&#34;max&#34;:[10]},&#34;pages&#34;:{}}}
  &lt;/script&gt;
&lt;/div&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#ROC Curve
comparison_test %&amp;gt;%
  roc_curve(Real,Class1) %&amp;gt;%
    autoplot()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Setting direction: controls &amp;lt; cases&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning in coords.roc(curv, x = unique(c(-Inf, options$predictor, Inf)), :
## An upcoming version of pROC will set the &amp;#39;transpose&amp;#39; argument to FALSE
## by default. Set transpose = TRUE explicitly to keep the current behavior,
## or transpose = FALSE to adopt the new one and silence this warning. Type
## help(coords_transpose) for additional information.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/Machine-Learning-Diploma-III/index_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#ROC AUC
comparison_test %&amp;gt;%
  roc_auc(Real,Class1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Setting direction: controls &amp;lt; cases&lt;/code&gt;&lt;/pre&gt;
&lt;div data-pagedtable=&#34;false&#34;&gt;
&lt;script data-pagedtable-source type=&#34;application/json&#34;&gt;
{&#34;columns&#34;:[{&#34;label&#34;:[&#34;.metric&#34;],&#34;name&#34;:[1],&#34;type&#34;:[&#34;chr&#34;],&#34;align&#34;:[&#34;left&#34;]},{&#34;label&#34;:[&#34;.estimator&#34;],&#34;name&#34;:[2],&#34;type&#34;:[&#34;chr&#34;],&#34;align&#34;:[&#34;left&#34;]},{&#34;label&#34;:[&#34;.estimate&#34;],&#34;name&#34;:[3],&#34;type&#34;:[&#34;dbl&#34;],&#34;align&#34;:[&#34;right&#34;]}],&#34;data&#34;:[{&#34;1&#34;:&#34;roc_auc&#34;,&#34;2&#34;:&#34;binary&#34;,&#34;3&#34;:&#34;0.7733382&#34;}],&#34;options&#34;:{&#34;columns&#34;:{&#34;min&#34;:{},&#34;max&#34;:[10]},&#34;rows&#34;:{&#34;min&#34;:[10],&#34;max&#34;:[10]},&#34;pages&#34;:{}}}
  &lt;/script&gt;
&lt;/div&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Calculated Model
full_advance$fit %&amp;gt;%
  tidy() &lt;/code&gt;&lt;/pre&gt;
&lt;div data-pagedtable=&#34;false&#34;&gt;
&lt;script data-pagedtable-source type=&#34;application/json&#34;&gt;
{&#34;columns&#34;:[{&#34;label&#34;:[&#34;term&#34;],&#34;name&#34;:[1],&#34;type&#34;:[&#34;chr&#34;],&#34;align&#34;:[&#34;left&#34;]},{&#34;label&#34;:[&#34;estimate&#34;],&#34;name&#34;:[2],&#34;type&#34;:[&#34;dbl&#34;],&#34;align&#34;:[&#34;right&#34;]},{&#34;label&#34;:[&#34;std.error&#34;],&#34;name&#34;:[3],&#34;type&#34;:[&#34;dbl&#34;],&#34;align&#34;:[&#34;right&#34;]},{&#34;label&#34;:[&#34;statistic&#34;],&#34;name&#34;:[4],&#34;type&#34;:[&#34;dbl&#34;],&#34;align&#34;:[&#34;right&#34;]},{&#34;label&#34;:[&#34;p.value&#34;],&#34;name&#34;:[5],&#34;type&#34;:[&#34;dbl&#34;],&#34;align&#34;:[&#34;right&#34;]}],&#34;data&#34;:[{&#34;1&#34;:&#34;(Intercept)&#34;,&#34;2&#34;:&#34;6.117855e-01&#34;,&#34;3&#34;:&#34;0.01993088&#34;,&#34;4&#34;:&#34;3.069536e+01&#34;,&#34;5&#34;:&#34;6.563661e-207&#34;},{&#34;1&#34;:&#34;AcctAge&#34;,&#34;2&#34;:&#34;1.274360e-01&#34;,&#34;3&#34;:&#34;0.02041803&#34;,&#34;4&#34;:&#34;6.241345e+00&#34;,&#34;5&#34;:&#34;4.338251e-10&#34;},{&#34;1&#34;:&#34;DDABal&#34;,&#34;2&#34;:&#34;-3.345807e-01&#34;,&#34;3&#34;:&#34;0.04233735&#34;,&#34;4&#34;:&#34;-7.902732e+00&#34;,&#34;5&#34;:&#34;2.728554e-15&#34;},{&#34;1&#34;:&#34;Checks&#34;,&#34;2&#34;:&#34;8.001763e-02&#34;,&#34;3&#34;:&#34;0.02764014&#34;,&#34;4&#34;:&#34;2.894979e+00&#34;,&#34;5&#34;:&#34;3.791843e-03&#34;},{&#34;1&#34;:&#34;Phone&#34;,&#34;2&#34;:&#34;1.188238e-01&#34;,&#34;3&#34;:&#34;0.02661229&#34;,&#34;4&#34;:&#34;4.464997e+00&#34;,&#34;5&#34;:&#34;8.006974e-06&#34;},{&#34;1&#34;:&#34;Teller&#34;,&#34;2&#34;:&#34;-1.992734e-01&#34;,&#34;3&#34;:&#34;0.02252055&#34;,&#34;4&#34;:&#34;-8.848515e+00&#34;,&#34;5&#34;:&#34;8.869169e-19&#34;},{&#34;1&#34;:&#34;SavBal&#34;,&#34;2&#34;:&#34;-6.805505e-01&#34;,&#34;3&#34;:&#34;0.04626114&#34;,&#34;4&#34;:&#34;-1.471106e+01&#34;,&#34;5&#34;:&#34;5.474173e-49&#34;},{&#34;1&#34;:&#34;ATMAmt&#34;,&#34;2&#34;:&#34;-3.045024e-01&#34;,&#34;3&#34;:&#34;0.03644366&#34;,&#34;4&#34;:&#34;-8.355428e+00&#34;,&#34;5&#34;:&#34;6.519615e-17&#34;},{&#34;1&#34;:&#34;POS&#34;,&#34;2&#34;:&#34;9.988335e-02&#34;,&#34;3&#34;:&#34;0.03999723&#34;,&#34;4&#34;:&#34;2.497256e+00&#34;,&#34;5&#34;:&#34;1.251584e-02&#34;},{&#34;1&#34;:&#34;POSAmt&#34;,&#34;2&#34;:&#34;-1.015285e-01&#34;,&#34;3&#34;:&#34;0.03693182&#34;,&#34;4&#34;:&#34;-2.749079e+00&#34;,&#34;5&#34;:&#34;5.976290e-03&#34;},{&#34;1&#34;:&#34;CCBal&#34;,&#34;2&#34;:&#34;6.859325e-02&#34;,&#34;3&#34;:&#34;0.01891700&#34;,&#34;4&#34;:&#34;3.626011e+00&#34;,&#34;5&#34;:&#34;2.878328e-04&#34;},{&#34;1&#34;:&#34;CCPurc&#34;,&#34;2&#34;:&#34;-2.941948e-02&#34;,&#34;3&#34;:&#34;0.02026686&#34;,&#34;4&#34;:&#34;-1.451605e+00&#34;,&#34;5&#34;:&#34;1.466114e-01&#34;},{&#34;1&#34;:&#34;Income&#34;,&#34;2&#34;:&#34;1.272866e-01&#34;,&#34;3&#34;:&#34;0.03479794&#34;,&#34;4&#34;:&#34;3.657877e+00&#34;,&#34;5&#34;:&#34;2.543134e-04&#34;},{&#34;1&#34;:&#34;LORes&#34;,&#34;2&#34;:&#34;-6.014610e-02&#34;,&#34;3&#34;:&#34;0.02823814&#34;,&#34;4&#34;:&#34;-2.129960e+00&#34;,&#34;5&#34;:&#34;3.317495e-02&#34;},{&#34;1&#34;:&#34;HMVal&#34;,&#34;2&#34;:&#34;-1.935050e-01&#34;,&#34;3&#34;:&#34;0.03770266&#34;,&#34;4&#34;:&#34;-5.132397e+00&#34;,&#34;5&#34;:&#34;2.860749e-07&#34;},{&#34;1&#34;:&#34;Age&#34;,&#34;2&#34;:&#34;-2.219778e-05&#34;,&#34;3&#34;:&#34;0.02288118&#34;,&#34;4&#34;:&#34;-9.701325e-04&#34;,&#34;5&#34;:&#34;9.992259e-01&#34;},{&#34;1&#34;:&#34;CRScore&#34;,&#34;2&#34;:&#34;1.337544e-02&#34;,&#34;3&#34;:&#34;0.02203018&#34;,&#34;4&#34;:&#34;6.071418e-01&#34;,&#34;5&#34;:&#34;5.437568e-01&#34;},{&#34;1&#34;:&#34;Dep&#34;,&#34;2&#34;:&#34;1.028510e-01&#34;,&#34;3&#34;:&#34;0.03356444&#34;,&#34;4&#34;:&#34;3.064284e+00&#34;,&#34;5&#34;:&#34;2.181913e-03&#34;},{&#34;1&#34;:&#34;DepAmt&#34;,&#34;2&#34;:&#34;-1.901625e-02&#34;,&#34;3&#34;:&#34;0.02478175&#34;,&#34;4&#34;:&#34;-7.673488e-01&#34;,&#34;5&#34;:&#34;4.428742e-01&#34;},{&#34;1&#34;:&#34;DDA_yes&#34;,&#34;2&#34;:&#34;2.707683e-01&#34;,&#34;3&#34;:&#34;0.02521098&#34;,&#34;4&#34;:&#34;1.074009e+01&#34;,&#34;5&#34;:&#34;6.597812e-27&#34;},{&#34;1&#34;:&#34;DirDep_yes&#34;,&#34;2&#34;:&#34;7.152448e-03&#34;,&#34;3&#34;:&#34;0.02218401&#34;,&#34;4&#34;:&#34;3.224146e-01&#34;,&#34;5&#34;:&#34;7.471386e-01&#34;},{&#34;1&#34;:&#34;NSF_yes&#34;,&#34;2&#34;:&#34;-2.370392e-02&#34;,&#34;3&#34;:&#34;0.02123988&#34;,&#34;4&#34;:&#34;-1.116010e+00&#34;,&#34;5&#34;:&#34;2.644177e-01&#34;},{&#34;1&#34;:&#34;Sav_yes&#34;,&#34;2&#34;:&#34;-2.547525e-01&#34;,&#34;3&#34;:&#34;0.02196270&#34;,&#34;4&#34;:&#34;-1.159932e+01&#34;,&#34;5&#34;:&#34;4.153464e-31&#34;},{&#34;1&#34;:&#34;ATM_yes&#34;,&#34;2&#34;:&#34;1.292603e-01&#34;,&#34;3&#34;:&#34;0.02414396&#34;,&#34;4&#34;:&#34;5.353733e+00&#34;,&#34;5&#34;:&#34;8.615816e-08&#34;},{&#34;1&#34;:&#34;CD_yes&#34;,&#34;2&#34;:&#34;-2.918515e-01&#34;,&#34;3&#34;:&#34;0.01859470&#34;,&#34;4&#34;:&#34;-1.569541e+01&#34;,&#34;5&#34;:&#34;1.625822e-55&#34;},{&#34;1&#34;:&#34;LOC_yes&#34;,&#34;2&#34;:&#34;6.110583e-03&#34;,&#34;3&#34;:&#34;0.01938014&#34;,&#34;4&#34;:&#34;3.153013e-01&#34;,&#34;5&#34;:&#34;7.525329e-01&#34;},{&#34;1&#34;:&#34;MM_yes&#34;,&#34;2&#34;:&#34;-2.589903e-01&#34;,&#34;3&#34;:&#34;0.01974444&#34;,&#34;4&#34;:&#34;-1.311713e+01&#34;,&#34;5&#34;:&#34;2.627075e-39&#34;},{&#34;1&#34;:&#34;CC_yes&#34;,&#34;2&#34;:&#34;-1.798393e-01&#34;,&#34;3&#34;:&#34;0.02157689&#34;,&#34;4&#34;:&#34;-8.334809e+00&#34;,&#34;5&#34;:&#34;7.762339e-17&#34;},{&#34;1&#34;:&#34;SDB_yes&#34;,&#34;2&#34;:&#34;-3.708755e-02&#34;,&#34;3&#34;:&#34;0.01901094&#34;,&#34;4&#34;:&#34;-1.950853e+00&#34;,&#34;5&#34;:&#34;5.107453e-02&#34;},{&#34;1&#34;:&#34;HMOwn_yes&#34;,&#34;2&#34;:&#34;-1.060297e-02&#34;,&#34;3&#34;:&#34;0.02920242&#34;,&#34;4&#34;:&#34;-3.630853e-01&#34;,&#34;5&#34;:&#34;7.165412e-01&#34;},{&#34;1&#34;:&#34;Branch_B2&#34;,&#34;2&#34;:&#34;-4.272629e-03&#34;,&#34;3&#34;:&#34;0.02524865&#34;,&#34;4&#34;:&#34;-1.692221e-01&#34;,&#34;5&#34;:&#34;8.656220e-01&#34;},{&#34;1&#34;:&#34;Branch_B3&#34;,&#34;2&#34;:&#34;-2.564723e-02&#34;,&#34;3&#34;:&#34;0.02535713&#34;,&#34;4&#34;:&#34;-1.011440e+00&#34;,&#34;5&#34;:&#34;3.118057e-01&#34;},{&#34;1&#34;:&#34;Branch_B1&#34;,&#34;2&#34;:&#34;2.605656e-02&#34;,&#34;3&#34;:&#34;0.02565672&#34;,&#34;4&#34;:&#34;1.015584e+00&#34;,&#34;5&#34;:&#34;3.098275e-01&#34;},{&#34;1&#34;:&#34;Branch_B7&#34;,&#34;2&#34;:&#34;3.878624e-02&#34;,&#34;3&#34;:&#34;0.02309364&#34;,&#34;4&#34;:&#34;1.679521e+00&#34;,&#34;5&#34;:&#34;9.305058e-02&#34;},{&#34;1&#34;:&#34;Branch_B5&#34;,&#34;2&#34;:&#34;-1.824560e-02&#34;,&#34;3&#34;:&#34;0.02531664&#34;,&#34;4&#34;:&#34;-7.206961e-01&#34;,&#34;5&#34;:&#34;4.710965e-01&#34;},{&#34;1&#34;:&#34;Branch_B6&#34;,&#34;2&#34;:&#34;-8.867298e-03&#34;,&#34;3&#34;:&#34;0.02270427&#34;,&#34;4&#34;:&#34;-3.905563e-01&#34;,&#34;5&#34;:&#34;6.961252e-01&#34;},{&#34;1&#34;:&#34;Branch_B4&#34;,&#34;2&#34;:&#34;-1.583160e-02&#34;,&#34;3&#34;:&#34;0.02902725&#34;,&#34;4&#34;:&#34;-5.454048e-01&#34;,&#34;5&#34;:&#34;5.854752e-01&#34;},{&#34;1&#34;:&#34;Branch_B16&#34;,&#34;2&#34;:&#34;1.673182e-01&#34;,&#34;3&#34;:&#34;0.02501004&#34;,&#34;4&#34;:&#34;6.690040e+00&#34;,&#34;5&#34;:&#34;2.231092e-11&#34;},{&#34;1&#34;:&#34;Branch_B8&#34;,&#34;2&#34;:&#34;-4.156275e-02&#34;,&#34;3&#34;:&#34;0.02204090&#34;,&#34;4&#34;:&#34;-1.885710e+00&#34;,&#34;5&#34;:&#34;5.933403e-02&#34;},{&#34;1&#34;:&#34;Res_suburb&#34;,&#34;2&#34;:&#34;2.037763e-02&#34;,&#34;3&#34;:&#34;0.02505362&#34;,&#34;4&#34;:&#34;8.133607e-01&#34;,&#34;5&#34;:&#34;4.160113e-01&#34;},{&#34;1&#34;:&#34;Res_urban&#34;,&#34;2&#34;:&#34;4.361963e-02&#34;,&#34;3&#34;:&#34;0.02516920&#34;,&#34;4&#34;:&#34;1.733056e+00&#34;,&#34;5&#34;:&#34;8.308567e-02&#34;}],&#34;options&#34;:{&#34;columns&#34;:{&#34;min&#34;:{},&#34;max&#34;:[10]},&#34;rows&#34;:{&#34;min&#34;:[10],&#34;max&#34;:[10]},&#34;pages&#34;:{}}}
  &lt;/script&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusions&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;&lt;span class=&#34;header-section-number&#34;&gt;3&lt;/span&gt; Conclusions&lt;/h1&gt;
&lt;p&gt;We have run a Machine Learning Process using:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;rsamples for splitting data.&lt;/li&gt;
&lt;li&gt;recipes for Pre-Processing.&lt;/li&gt;
&lt;li&gt;parsnip to fit the model&lt;/li&gt;
&lt;li&gt;yardstick to measure the performance.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Finally 41 variables were kept getting a 72% of accuracy and a 77.3% of ROC AUC.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
