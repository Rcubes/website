<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>admin on datacubeR</title>
    <link>/authors/admin/</link>
    <description>Recent content in admin on datacubeR</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright> &lt;i class=&#39;fab fa-creative-commons fa-2x&#39;&gt;&lt;/i&gt;&lt;i class=&#39;fab fa-creative-commons-by fa-2x&#39;&gt;&lt;/i&gt;&lt;i class=&#39;fab fa-creative-commons-sa fa-2x&#39;&gt;&lt;/i&gt;&lt;br&gt;&amp;copy;Alfonso Tobar. Made with &lt;i class=&#39;fab fa-r-project&#39;&gt;&lt;/i&gt; Blogdown Package.</copyright>
    <lastBuildDate>Mon, 20 Jul 2020 00:50:00 +0000</lastBuildDate>
    
	<atom:link href="/authors/admin/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Using Naive Bayes as a Baseline Model</title>
      <link>/publication/problem-11/</link>
      <pubDate>Mon, 20 Jul 2020 00:50:00 +0000</pubDate>
      
      <guid>/publication/problem-11/</guid>
      <description>Naive bayes The other day I had to prepare a class showing the benefits of using Naive Bayes. I have to say this is not a super powerful model, mainly because it makes assumptions that are most of the time not true. Nevertheless, I noticed this can be an excellent way to create a baseline model. It is easy, not very complicated to implement and the best thing is that is super fast.</description>
    </item>
    
    <item>
      <title>I will start teaching</title>
      <link>/post/teaching/</link>
      <pubDate>Mon, 20 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>/post/teaching/</guid>
      <description>Academia Desafio LatamBecause of Coronavirus pandemic I started to look for opportunities. I‚Äôm not sure if it is the right moment to do it, but I found the opportunity to start teaching Python and I took it. I applied with no hopes, and I received a reply message sharing the Data Science program syllabus plus an invitation to a technical interview.
I won‚Äôt spoil the interview, but I found it so difficult.</description>
    </item>
    
    <item>
      <title>How to use MLflow with Python</title>
      <link>/post/mlflow/</link>
      <pubDate>Mon, 13 Jul 2020 00:50:00 +0000</pubDate>
      
      <guid>/post/mlflow/</guid>
      <description>How to use MLflow I have to say that I love modeling, but at the same time it demands the best of me in terms of being organized. I¬¥m a mess, and that definitely is not helpful when modeling. So I had to put lots of efforts on creating my own folder system that helps me to organize my code, my data and my outputs. But even having all of that there is something I couldn&amp;rsquo;t managed to organize and those are my experiments.</description>
    </item>
    
    <item>
      <title>Reusable Plotting Functions in Python</title>
      <link>/publication/problem-10/</link>
      <pubDate>Sun, 05 Jul 2020 00:50:00 +0000</pubDate>
      
      <guid>/publication/problem-10/</guid>
      <description>Creating reusable plotting Functions In my new job I¬¥ve noticed they like to explain variables impact into some target in the following way:
Normally we have a natural Rate of an Event happening shown as this TN dashed line. And you have a particular variable that is splitted into Categories showing what is the specific Rate of the Event by Category.
Since this is happening so often, I decided to build a simple function to avoid all the work behind the scenes.</description>
    </item>
    
    <item>
      <title>Calculating Recency using dplyr</title>
      <link>/publication/problem-9/</link>
      <pubDate>Tue, 04 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>/publication/problem-9/</guid>
      <description>The ProblemWe have an Intern working on his Thesis Project in our office. He needed to calculate Customer recency, meaning he needed to know the amount of months since the last time the Customer made a Purchase. This was quite intriguing to me because it needs to combine some windows scoped functions with group by and some other things.
This is the problem with the expected solution:</description>
    </item>
    
    <item>
      <title>R vs Python, Part II</title>
      <link>/post/r-vs-python-ii/</link>
      <pubDate>Mon, 03 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>/post/r-vs-python-ii/</guid>
      <description>During last blog post I shared my bad experiences with R in these late days. This doesn‚Äôt mean I hate R at all, but it does mean that I‚Äôm eagerly learning Python to supply some of the R deficencies.
In this 3 weeks of intensive Python learning I‚Äôve learned a lot and here are some things on why moving to Python.
The main advantage of the Python Data science environment is that you can find everything condesnsed into the Scipy stack.</description>
    </item>
    
    <item>
      <title>R vs Python</title>
      <link>/post/r-vs-python/</link>
      <pubDate>Wed, 29 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>/post/r-vs-python/</guid>
      <description>Catching up about meI‚Äôve been working in my new job for the last two months, I‚Äôve had some pros and some cons but that will be another day‚Äôs discussion. The reason I‚Äôm writing about this is because in my new role I have to create a lot of ML models and sadly, and I really mean sadly, R is not suited for that. And it seems Python is.</description>
    </item>
    
    <item>
      <title>I got a new job</title>
      <link>/post/new-job/</link>
      <pubDate>Wed, 06 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/new-job/</guid>
      <description>My new JobMy working relationship with Evalueserve ended the past June and I just dedicated to finish my Thesis. On the first days of October I just started to apply to different Jobs, I have to say my first option was trying to get a Job at H2o, but I¬¥m not there yet.
The thing is that after the first Interview I knew this would be my new Company, I felt some kind of feeling saying ‚Äúyou will work here‚Äù (although I had some hesitation).</description>
    </item>
    
    <item>
      <title>Dealing with dates</title>
      <link>/publication/problem-7/</link>
      <pubDate>Wed, 30 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>/publication/problem-7/</guid>
      <description>The ProblemHere is the challenge:
Calculate the time difference between Max and Min Dates found in a date vector.
library(tidyverse)date_vec &amp;lt;- c(&amp;quot;2019/10/24 10:00:00&amp;quot;,&amp;quot;2019/10/23 11:00:00&amp;quot;,&amp;quot;2019/10/25 12:00:00&amp;quot;) The SolutionThe thing is super easy to get, but the idea is to create a pipeline that can calculate this in just a series of steps:
library(lubridate)date_vec %&amp;gt;%#Transforming characters into dates using ymd for dates and hms for timeymd_hms() %&amp;gt;%#range() retrieves max and min daterange() %&amp;gt;%#Calculate the time differencediff() %&amp;gt;%#Transform into lubridate duration object %&amp;gt;%as.</description>
    </item>
    
    <item>
      <title>Unique Id Challenge</title>
      <link>/publication/problem-8/</link>
      <pubDate>Wed, 30 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>/publication/problem-8/</guid>
      <description>The ProblemAnother Twitter Challenge:
#rstats I&amp;#39;m sure there&amp;#39;s an elegant solution that I&amp;#39;m just totally missing. How do I create a unique episode_ID that increases by 1 for instances where episode_flag == &amp;quot;new&amp;quot; but just repeats the value from the row above when episode_flag == &amp;quot;same&amp;quot;? pic.twitter.com/Dl5ZtAiE7J
&amp;mdash; Jessica Streeter (@phillynerd) October 30, 2019  The SolutionIt is almost there, I just added a couple of lines to get the expected output elegantly:</description>
    </item>
    
    <item>
      <title>Transposing a dataframe</title>
      <link>/publication/problem-6/</link>
      <pubDate>Thu, 24 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>/publication/problem-6/</guid>
      <description>The ProblemHere is the challenge:
data &amp;lt;- data.frame(&amp;quot;id&amp;quot; = c(901, 902, 903, &amp;quot;age&amp;quot;, &amp;quot;gender&amp;quot;, &amp;quot;language&amp;quot;),&amp;quot;rater1&amp;quot; = c(7, 9, 9, 21, 1, 1),&amp;quot;rater2&amp;quot; = c(9, 9, 9, 39, 2, 2),&amp;quot;rater3&amp;quot; = c(9, 9, 9, 38, 2, 1),&amp;quot;rater4&amp;quot; = c(9, 9, 9, 33, 2, 1),&amp;quot;rater5&amp;quot; = c(2, 9, 9, 21, 2, 1))Filter all the ratings with gender 1, or language 1, or gender 1 AND language 1.</description>
    </item>
    
    <item>
      <title>List Challenge</title>
      <link>/publication/problem-5/</link>
      <pubDate>Sat, 19 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>/publication/problem-5/</guid>
      <description>The ProblemThis is simple, If Names of List are found in List B then Replace:
a &amp;lt;- list(x = 1, y = TRUE, z = &amp;quot;a&amp;quot;)b &amp;lt;- list(x = 2, z = &amp;quot;b&amp;quot;)expected &amp;lt;- list(x = 2, y = TRUE, z = &amp;quot;b&amp;quot;)The SolutionIt was hard to think in something simple, because the problem is not as complicated, it is just List is a complicated object to deal with, but I came with this:</description>
    </item>
    
    <item>
      <title>Ugly Untied Dataset</title>
      <link>/publication/problem-4/</link>
      <pubDate>Sat, 19 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>/publication/problem-4/</guid>
      <description>Even though the Data looks messy and an Intruitive solution didn¬¥t pop up inmediately, It was relatively short to fix.
The ProblemI want to save some words so I‚Äôll go to the source
Hey #rstats peeps. I have ~36 tables like this extracted from the LCMM üì¶ results. I need to tidy it. I want 5 rows with the values for intercept and sofa_study_day in individual columns.</description>
    </item>
    
    <item>
      <title>Missing Value Imputation</title>
      <link>/publication/problem-1/</link>
      <pubDate>Wed, 16 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>/publication/problem-1/</guid>
      <description>Surfing at Stack Overflow I noticed a problem that I found interesting to solve:The following Data was presented:
The ProblemThe following Data is presented:
sample &amp;lt;-structure(list(`Country Name` = c(&amp;quot;Aruba&amp;quot;,&amp;quot;Afghanistan&amp;quot;,&amp;quot;Angola&amp;quot;,&amp;quot;Albania&amp;quot;,&amp;quot;Andorra&amp;quot;,&amp;quot;Arab World&amp;quot;,&amp;quot;United Arab Emirates&amp;quot;,&amp;quot;Argentina&amp;quot;,&amp;quot;Armenia&amp;quot;,&amp;quot;American Samoa&amp;quot;,&amp;quot;Antigua and Barbuda&amp;quot;,&amp;quot;Australia&amp;quot;),`Country Code` = c(&amp;quot;ABW&amp;quot;,&amp;quot;AFG&amp;quot;,&amp;quot;AGO&amp;quot;,&amp;quot;ALB&amp;quot;,&amp;quot;AND&amp;quot;,&amp;quot;ARB&amp;quot;,&amp;quot;ARE&amp;quot;,&amp;quot;ARG&amp;quot;,&amp;quot;ARM&amp;quot;,&amp;quot;ASM&amp;quot;,&amp;quot;ATG&amp;quot;,&amp;quot;AUS&amp;quot;),`2007` = c(5.</description>
    </item>
    
    <item>
      <title>Tidy Evaluation</title>
      <link>/publication/problem-2/</link>
      <pubDate>Wed, 16 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>/publication/problem-2/</guid>
      <description>Navigating Twitter I found this other Problem:
The ProblemThe following dummy_function is presented:
library(dplyr)#&amp;gt; a &amp;lt;- sample(letters[1:5], 500, rep = TRUE)b &amp;lt;- sample(1:10, 500, rep = TRUE)df1 &amp;lt;- data.frame(a, b)dummy_function &amp;lt;- function(data, var1, var2){# Creating summary statisticsdf &amp;lt;- data %&amp;gt;%group_by(var1, var2) %&amp;gt;%summarise(n=n()) %&amp;gt;%group_by(var1) %&amp;gt;%mutate(perc=100*n/sum(n))df}dummy_function(df1, a, b)#&amp;gt; Error: Column `var1` is unknownCreated by the reprex package (v0.</description>
    </item>
    
    <item>
      <title>Why this is failing?</title>
      <link>/publication/problem-3/</link>
      <pubDate>Wed, 16 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>/publication/problem-3/</guid>
      <description>This is a pretty typical issue. Specially when you have dealing with data a long time you just stop seeing obvious things, and you just can¬¥t find solution to inexistant problems. For instance:
mtcars %&amp;gt;%filter(cyl &amp;lt; 4){&#34;columns&#34;:[{&#34;label&#34;:[&#34;mpg&#34;],&#34;name&#34;:[1],&#34;type&#34;:[&#34;dbl&#34;],&#34;align&#34;:[&#34;right&#34;]},{&#34;label&#34;:[&#34;cyl&#34;],&#34;name&#34;:[2],&#34;type&#34;:[&#34;dbl&#34;],&#34;align&#34;:[&#34;right&#34;]},{&#34;label&#34;:[&#34;disp&#34;],&#34;name&#34;:[3],&#34;type&#34;:[&#34;dbl&#34;],&#34;align&#34;:[&#34;right&#34;]},{&#34;label&#34;:[&#34;hp&#34;],&#34;name&#34;:[4],&#34;type&#34;:[&#34;dbl&#34;],&#34;align&#34;:[&#34;right&#34;]},{&#34;label&#34;:[&#34;drat&#34;],&#34;name&#34;:[5],&#34;type&#34;:[&#34;dbl&#34;],&#34;align&#34;:[&#34;right&#34;]},{&#34;label&#34;:[&#34;wt&#34;],&#34;name&#34;:[6],&#34;type&#34;:[&#34;dbl&#34;],&#34;align&#34;:[&#34;right&#34;]},{&#34;label&#34;:[&#34;qsec&#34;],&#34;name&#34;:[7],&#34;type&#34;:[&#34;dbl&#34;],&#34;align&#34;:[&#34;right&#34;]},{&#34;label&#34;:[&#34;vs&#34;],&#34;name&#34;:[8],&#34;type&#34;:[&#34;dbl&#34;],&#34;align&#34;:[&#34;right&#34;]},{&#34;label&#34;:[&#34;am&#34;],&#34;name&#34;:[9],&#34;type&#34;:[&#34;dbl&#34;],&#34;align&#34;:[&#34;right&#34;]},{&#34;label&#34;:[&#34;gear&#34;],&#34;name&#34;:[10],&#34;type&#34;:[&#34;dbl&#34;],&#34;align&#34;:[&#34;right&#34;]},{&#34;label&#34;:[&#34;carb&#34;],&#34;name&#34;:[11],&#34;type&#34;:[&#34;dbl&#34;],&#34;align&#34;:[&#34;right&#34;]}],&#34;data&#34;:[],&#34;options&#34;:{&#34;columns&#34;:{&#34;min&#34;:{},&#34;max&#34;:[10]},&#34;rows&#34;:{&#34;min&#34;:[10],&#34;max&#34;:[10]},&#34;pages&#34;:{}}}You want to get the rows having cyl less or equal to 4 and for quite a while you keep getting 0 results.Obviously something is wrong with the code but you just can¬¥t notice it.</description>
    </item>
    
    <item>
      <title>Latin R (Days 2 and 3)</title>
      <link>/post/latin-r-ii/</link>
      <pubDate>Mon, 30 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/latin-r-ii/</guid>
      <description>Latin R (Conferences Days)Today the Conference Days just got started, and I have to say I watched some really impresive presentations and Data Products.
Day 1 started with a UAI local presenter talking about Sports Analytics in R, then a huge presentation by Mine Cetinkaya about Teaching R to move to specific small presentation in parallel so I was able just to watch half of the Presentations.
Day 2 started with a UC local presenter talking about applying Data Science in R to Government Data, then Erin Ledell talked about H2o to move forward to the small presentations in Parallel.</description>
    </item>
    
    <item>
      <title>Latin R (Day 1)</title>
      <link>/post/latin-r-i/</link>
      <pubDate>Wed, 25 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/latin-r-i/</guid>
      <description>Latin R (Tutorials Day)Today Latin R just got started. It was really impressive to see how many people actually uses R. I have to say the popularity of Python in Data Science has always been something that worries me tons, but today I was able to see a lot of other Areas where people actually use R. Probably I was one of the few people working in Data Science there.</description>
    </item>
    
    <item>
      <title>Latin R</title>
      <link>/post/latin-r/</link>
      <pubDate>Tue, 24 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/latin-r/</guid>
      <description>Latin RLatin R is a conference organized by RLadies Latam and is the oportunity we have here in Chile to get acquainted about the last R breakthrough and how is being using in Research, companies, etc.They also provide a full day of Tutorials and of course important keynotes are invited to come over. This year I think is huge, because 3 Main R users are coming:
Mine √áetinkaya-RundelShe is one of the most important persons involved into R Teaching.</description>
    </item>
    
    <item>
      <title>My Thesis</title>
      <link>/project/my-thesis/</link>
      <pubDate>Mon, 23 Sep 2019 00:00:00 -0300</pubDate>
      
      <guid>/project/my-thesis/</guid>
      <description>Coming up with an Interesting Thesis Project is not easy at all. Actually I had 3 different projets and 5 different professors. None of them were really interested in my propositions. Thank God I found Dr. Marcos Valdebenito. He is really interested in Reliability Analysis in Structures and Study the Response of Random Field Variables into Strutures, you can learn more about his work on his website. Once I talked to him about I was doing in my former job he was really interested in applying Machine Learning techniques to solve this kind of problems.</description>
    </item>
    
    <item>
      <title>The Stiffness Method</title>
      <link>/project/stiffness-method/</link>
      <pubDate>Mon, 23 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>/project/stiffness-method/</guid>
      <description>The MethodThe ProblemRcpp BasicsCreating an Rcpp fileStiffness MethodStiff Matrix by ElementActive DoF AssemblyConnectivity ArrayStiffness Matrix AssemblyLoad Vector AssemblySolving the ProblemConclusionsThe MethodThe Rayleigh Ritz Method is nothing but applying Finite Elements to Structural problems. Basically you split your structure into smaller structures that can easily be solved By solving, I mean, Calculate the specific stifness of the Structure in order to determine how the loads affects the structure.</description>
    </item>
    
    <item>
      <title>My Final Project at the ML Diploma (Part III)</title>
      <link>/project/machine-learning-diploma-iii/</link>
      <pubDate>Tue, 27 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>/project/machine-learning-diploma-iii/</guid>
      <description>1 Tidymodels1.1 Spliting the Data1.2 Pre Processing2 Create the Logistic Regression3 ConclusionsNow we have an idea on how the data looks like it is time to Model.
1 TidymodelsI¬¥m a huge fan of tidymodels framework and the way Max Kuhn has put together all of this system. I¬¥ll be using several packages from this framework in order to show different steps of the Machine Learning Process.</description>
    </item>
    
    <item>
      <title>My Final Project at the ML Diploma (Part II)</title>
      <link>/project/machine-learning-diploma-ii/</link>
      <pubDate>Thu, 08 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>/project/machine-learning-diploma-ii/</guid>
      <description>1 Checking Numerical Distribution2 Checking Categorical Variables3 Chi-Square Test4 ConclusionLast time we conducted a high level cleansing of the data. Now it¬¥s time to understand what is going on in it. In order to do that we¬¥ll use a lot ggplot to visualize the data.
1 Checking Numerical DistributionIn order to do this I should pick Numerical Variables one by one and create a ggplot.</description>
    </item>
    
    <item>
      <title>My Final Project at the ML Diploma (Part I)</title>
      <link>/project/machine-learning-diploma/</link>
      <pubDate>Fri, 19 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>/project/machine-learning-diploma/</guid>
      <description>1 Importing Data2 Redefining Categorical Variables3 Discovering Missing Values4 ConclusionDuring my Machine Learning Diploma I had the chance to work on a very interesting project that was actually created in SAS. Of course I absolutely refused to use that old fashioned tool and I move everything to R.
I will try to demonstrate as much of the packages I used to perform this analysis.</description>
    </item>
    
    <item>
      <title>Propuesta Redes Convolucionales</title>
      <link>/project/convolutional-nets-sp/memoria-1/</link>
      <pubDate>Thu, 11 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>/project/convolutional-nets-sp/memoria-1/</guid>
      <description>Redes Convolucionales¬øC√≥mo se relaciona esto con las Redes Convolucionales?¬øC√≥mo se va especializando la red para ser cada vez m√°s detallista?¬øC√≥mo se relaciona este problema con Estructuras?El Paper de FinolSoluci√≥nPuntos Interesantes para la Investigaci√≥n.1era Sugerencia (Quiz√°s no para la Memoria, pero para seguir investigando)2da Sugerencia3era Sugerencia.4ta Sugerencia ‚ÄúCrear Im√°genes Estructurales‚ÄùRedes ConvolucionalesLas redes convolucionales es un tipo de Red que esta especializada principalmente en extraer caracter√≠sticas de im√°genes.</description>
    </item>
    
    <item>
      <title>Activation Functions</title>
      <link>/project/activation-functions/activation-functions/</link>
      <pubDate>Mon, 08 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>/project/activation-functions/activation-functions/</guid>
      <description>Activation FunctionsIdentityStep FunctionLinear FunctionSigmoid FunctionHyperbolic TangentReLULeaky ReLUSoftmaxHow to choose the perfect Activation function?Activation FunctionsActivation functions are one of the most important characteristic of ANN. They basically decide whether a neuron should be activated or not. When a particular threshold is reached the Neuron will fire, meaning they will transmit the input signal to the next layer of the Network.</description>
    </item>
    
    <item>
      <title>Intro to Neural Networks</title>
      <link>/project/neural-nets-101/intro-to-nn/</link>
      <pubDate>Sun, 07 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>/project/neural-nets-101/intro-to-nn/</guid>
      <description>What is an Artificial Neural Network?Basic StructureWhat Problems can Neural Networks solve?ClassificationRegressionTypical Problems solved with Neural NetworksConclusionWhat is an Artificial Neural Network?The Picture you see up there is far a way from what a real Neural Network looks like:
Actually it is more similar to something like this:
Figure 1: Multi-Layer PerceptronThe configuration showed above is nothing but a visual representation of serial Matrix Multiplications.</description>
    </item>
    
    <item>
      <title>Deep Learning</title>
      <link>/post/deep-learning/</link>
      <pubDate>Wed, 27 Mar 2019 00:50:00 +0000</pubDate>
      
      <guid>/post/deep-learning/</guid>
      <description>Deep Learning Well, I got to know Deep Learning by chance. I remember to have had a College subject called Operational Investigation Fundamentals and they taugth Artifical Intelligence algorithms. Neural networks were mentioned but I never thought I could even understand what they were about. During my first real job (as a quasi-Engineer) I always thougth I never paid sufficient attention to that subject. The subject basically covered some optimization models and for some reason AI was there, just sky-high level mentions in some classes.</description>
    </item>
    
    <item>
      <title>My Thesis Project</title>
      <link>/post/my-thesis/</link>
      <pubDate>Wed, 27 Mar 2019 00:50:00 +0000</pubDate>
      
      <guid>/post/my-thesis/</guid>
      <description>Why am I not graduated yet? Graduation is something we all are longing. Well, I recognize this is something I&amp;rsquo;ve been evading. The main reason is because I&amp;rsquo;m not working on what I studied. But, what the hell, I think I like Data Science.
Ok, Long Story Short&amp;hellip; I was about to study Mathematical Engineering but I asked myself, where can I possibly work as a Mathematical Engineer ? (In my current job, obviously üòÖ)</description>
    </item>
    
    <item>
      <title></title>
      <link>/author/admin/</link>
      <pubDate>Mon, 20 Jul 2020 00:35:58 -0400</pubDate>
      
      <guid>/author/admin/</guid>
      <description>I¬¥m a Civil Engineer, but I got to know Data Science and I just loved it. I¬¥ve worked the last 5 years as an R and Python developer, involved in almost every aspect of the Data Science Workflow.
I love teaching and I aspire to eventually teach I&amp;rsquo;m currently teaching Intro to Python, Data Science Fundamentals and Machine Learning at Academia Desafio Latam to help Data Scientist around the world in Chile to get better.</description>
    </item>
    
  </channel>
</rss>